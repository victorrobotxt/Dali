--- GLASHAUS PROJECT DUMP ---
Fri Dec 19 21:29:07 EET 2025


--- GIT HISTORY ---
* 698eb25 (HEAD -> main) refactor(core): implement hybrid scraping fallback and multimodal AI forensics
* 6f470a6 refactor(core): production hardening, type safety, and architecture cleanup
* 0f7d54d refactor(core): production hardening, type safety, and architecture cleanup
* d13df83 refactor(core): harden security, async concurrency, and financial precision
* 5a71d4d refactor(core): promote prototype to production-ready architecture
* fdd6519 docs: update architecture, API contract, and debt log to match V1 state
* a107438 feat(core): implement forensic analysis and anti-manipulation logic
* 2f79d2e removed junk
* ed4950e feat(forensics): harden backend with LexSofia logic and municipal registry strikes
* 00b1e10 feat(reporting): integrate forensic registry checks into Legal Brief generation
* e3f1eaf fix(services): implement circuit breakers for government registry availability
* 6c7c90c feat(forensics): implement live registry verification and v2 risk engine
* 21bbc86 fix(core): harden worker db sessions, strict config, and normalize risk logic
* 2e8f2fa refactor(core): harden backend architecture and implement forensic logic
* f639780 feat(legal): implement legal forensic engine and solicitor report generation
* 6489783 feat(core): harden task resilience, abstract providers, and add storage layer
* a087b30 feat(backend): implement vision layer, harden worker logic, and add regex parsing
* 4987d66 feat(infra): add Nginx gateway, CORS, and live scraping logic
* ae76a80 refactor(core): upgrade architecture to Celery/Redis and harden AI logic
* b7f3797 refactor(core): migrate to Redis/Celery queue and add Alembic migrations


--- FILE STRUCTURE ---
.
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ README.md
â”œâ”€â”€ alembic.ini
â”œâ”€â”€ bypass_audit.py
â”œâ”€â”€ cookies.txt
â”œâ”€â”€ db
â”‚Â Â  â”œâ”€â”€ migration_001_status_workflow.sql
â”‚Â Â  â”œâ”€â”€ migration_002_fix_currency.sql
â”‚Â Â  â”œâ”€â”€ migrations
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ env.py
â”‚Â Â  â”‚Â Â  â””â”€â”€ versions
â”‚Â Â  â””â”€â”€ schema_v1.sql
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ docs
â”‚Â Â  â”œâ”€â”€ ARCHITECTURE.md
â”‚Â Â  â”œâ”€â”€ LASTENHEFT_DE.md
â”‚Â Â  â”œâ”€â”€ TECHNICAL_DEBT.md
â”‚Â Â  â””â”€â”€ api_contract.yaml
â”œâ”€â”€ forensics
â”‚Â Â  â”œâ”€â”€ headers.txt
â”‚Â Â  â””â”€â”€ page_utf8.html
â”œâ”€â”€ forensics_dump.html
â”œâ”€â”€ glashaus_context.txt
â”œâ”€â”€ imot_simulation.html
â”œâ”€â”€ manual_session_audit.py
â”œâ”€â”€ nginx
â”‚Â Â  â””â”€â”€ nginx.conf
â”œâ”€â”€ prompts
â”‚Â Â  â””â”€â”€ detective_prompt_v1.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ scraper_service.py
â”œâ”€â”€ scripts
â”‚Â Â  â””â”€â”€ context_dump.sh
â”œâ”€â”€ src
â”‚Â Â  â”œâ”€â”€ __init__.py
â”‚Â Â  â”œâ”€â”€ api
â”‚Â Â  â”‚Â Â  â””â”€â”€ routes.py
â”‚Â Â  â”œâ”€â”€ core
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ config.py
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ logger.py
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ patterns.py
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ sofia_data.py
â”‚Â Â  â”‚Â Â  â””â”€â”€ utils.py
â”‚Â Â  â”œâ”€â”€ db
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ models.py
â”‚Â Â  â”‚Â Â  â””â”€â”€ session.py
â”‚Â Â  â”œâ”€â”€ main.py
â”‚Â Â  â”œâ”€â”€ models
â”‚Â Â  â”œâ”€â”€ schemas.py
â”‚Â Â  â”œâ”€â”€ services
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ ai_engine.py
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ base_provider.py
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ cadastre_service.py
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ city_risk_service.py
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ compliance_service.py
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ forensics_service.py
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ geospatial_service.py
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ legal_engine.py
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ report_generator.py
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ repository.py
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ risk_engine.py
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ scraper_mvp.py
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ scraper_service.py
â”‚Â Â  â”‚Â Â  â””â”€â”€ storage_service.py
â”‚Â Â  â”œâ”€â”€ tasks.py
â”‚Â Â  â””â”€â”€ worker.py
â”œâ”€â”€ storage
â”‚Â Â  â””â”€â”€ archive
â”œâ”€â”€ tests
â”‚Â Â  â””â”€â”€ test_api.py
â””â”€â”€ waf_challenge.html

18 directories, 54 files


--- FILE CONTENTS ---


=========================================
FILE: ./docs/ARCHITECTURE.md
=========================================
# System Architecture

## Core Logic Flow (Forensic Loop)
The system uses an Event-Driven architecture to orchestrate parallel forensic checks.

1. **Ingest & Normalize:** - Scraper Service fetches URL (handling `windows-1251` encoding).
   - URLs are normalized (mobile subdomain enforcement) and deduplicated via content hash.
   
2. **The "Forensic Audit" Task (Celery Worker):**
   Unlike the initial design, the system now runs a **consolidated parallel audit** rather than a tiered fallback.
   
   - **Step A: Text Analysis (Gemini Flash):** Extracts unstructured data (Address, Construction Year, Atelier status).
   - **Step B: Official Registry Checks (Async/Parallel):**
     - **Cadastre Service:** Verifies official area vs advertised area using the extracted address.
     - **City Risk Service (NAG):** Checks Sofia Municipal records for Expropriation (seizure) risks.
     - **Compliance Service:** Verifies "Act 16" (Commissioning Certificate) status against the cadastral ID.
   - **Step C: Risk Engine V2:**
     - Merges all data points to calculate a composite `Risk Score` (0-100).
     - Identifies "Fatal" flags (e.g., Expropriation = 100% Risk).

3. **Report Generation:** - `AttorneyReportGenerator` synthesizes a human-readable legal brief from the structured forensic data.

## Tech Stack
- **Service Layer:** Python 3.11 (FastAPI)
- **Asynchronous Task Queue:** Celery + Redis
- **Database:** PostgreSQL + PostGIS (Spatial data)
- **Resilience:** Circuit Breakers implemented for Government Registry downtime (handling `httpx.ConnectError`).

## Critical Components
| Component | Function | Status |
| :--- | :--- | :--- |
| **Risk Engine** | Calculates score based on Area Fraud, Legal Status (Atelier), and Expropriation. | âœ… Implemented (V2) |
| **Forensics Service** | Manages sessions with `nag.sofia.bg` and `kais.cadastre.bg`. | âœ… Implemented |
| **Storage Service** | Archives listing images to disk/S3 for evidence preservation. | âœ… Implemented |


=========================================
FILE: ./docs/api_contract.yaml
=========================================
openapi: 3.0.0
info:
  title: Glashaus API
  version: 1.0.0
paths:
  /audit/url:
    post:
      summary: Initiate an Audit for a specific Listing URL
      requestBody:
        content:
          application/json:
            schema:
              type: object
              properties:
                url:
                  type: string
                  format: uri
      responses:
        '200':
          description: Audit Queued
          content:
            application/json:
              schema:
                type: object
                properties:
                  listing_id:
                    type: integer
                  status:
                    type: string
                    example: "QUEUED_IN_REDIS"

  /reports/{listing_id}:
    get:
      summary: Retrieve Forensic Report & Risk Score
      responses:
        '200':
          description: Detailed Audit Report
          content:
            application/json:
              schema:
                type: object
                properties:
                  report_id:
                    type: integer
                  status:
                    type: string
                    enum: [PENDING, PROCESSING, VERIFIED, MANUAL_REVIEW, REJECTED]
                  risk_score:
                    type: integer
                    description: 0-100 (100 is Toxic/Fatal)
                  cost:
                    type: float
                  manual_notes:
                    type: string
                  discrepancies:
                    type: object
                    properties:
                      flags:
                        type: array
                        items: 
                          type: string
                        example: ["CRITICAL: Property is listed for EXPROPRIATION.", "LEGAL: Atelier status."]
                      forensics:
                        type: object
                        properties:
                          city_risk:
                            type: object
                            properties:
                              is_expropriated: 
                                type: boolean
                              registry_status:
                                type: string
                          compliance:
                            type: object
                            properties:
                              has_act16:
                                type: boolean
                          cadastre:
                            type: object
                            properties:
                              official_area:
                                type: number
                              diff_percent:
                                type: number


=========================================
FILE: ./docs/LASTENHEFT_DE.md
=========================================
# LASTENHEFT: Projekt Glashaus
**Version:** 1.0.0
**Status:** In Entwicklung

## 1. Einleitung
Das Projekt "Glashaus" ist eine automatisierte Due-Diligence-Plattform fÃ¼r den Immobilienmarkt in Sofia. Ziel ist die Beseitigung von Informationsasymmetrien durch den Einsatz von OSINT und KI-gestÃ¼tzter Datenanalyse.

## 2. Ist-Zustand (Problemstellung)
- **Datenfragmentierung:** Grundbuch (Registry), Kataster (Cadastre) und Gemeinde agieren in Silos.
- **Intransparenz:** Immobilienanzeigen enthalten oft ungenaue FlÃ¤chenangaben und verschleierte Adressen.
- **Prozessineffizienz:** Manuelle PrÃ¼fungen sind teuer und langsam.

## 3. Soll-Zustand (LÃ¶sung)
Ein Microservices-System, das folgende Kernfunktionen bietet:
1.  **Automatische Adress-Deduktion:** Ermittlung der exakten Adresse aus unstrukturierten Anzeigentexten und Bildern.
2.  **Soll/Ist-Abgleich:** Automatischer Vergleich von Maklerangaben (Anzeige) mit amtlichen Katasterdaten.
3.  **Risikobewertung:** Algorithmische Berechnung eines "Risk Scores" (0-100).

## 4. Technische Anforderungen
- **Architektur:** Event-Driven Microservices (Python/FastAPI).
- **Datenbank:** PostgreSQL mit PostGIS fÃ¼r Geodatenverarbeitung.
- **KI-Integration:**
    - *Tier 1:* Textanalyse (Low Cost / Gemini Flash).
    - *Tier 2:* Visuelle Analyse (High Cost / Gemini Pro).

## 5. Nicht-funktionale Anforderungen
- **Idempotenz:** Wiederholte Uploads dÃ¼rfen keine Datenkorruption verursachen.
- **Skalierbarkeit:** Das System muss Warteschlangen (Queues) nutzen, um Lastspitzen bei Scrapern abzufangen.


=========================================
FILE: ./docs/TECHNICAL_DEBT.md
=========================================
# TECHNICAL DEBT LOG

## Critical Severity (Must Fix Before Beta)

### 1. Hardcoded Secrets (Config)
- **Location:** `src/core/config.py`
- **Issue:** `GEMINI_API_KEY` defaults to "mock-key". While validated at runtime, this is bad practice.
- **Fix:** Remove default value entirely and force `.env` loading.

### 2. Scraper Fragility (DOM Coupling)
- **Location:** `src/services/scraper_service.py` & `forensic_check.py`
- **Issue:** Logic relies on specific HTML IDs (e.g., `id='price'`, `id='description_div'`).
- **Risk:** High. If `imot.bg` updates their frontend classes, the "Space Hack" and Price normalization logic will fail silently.
- **Fix:** Implement multi-selector fallbacks or move strictly to Visual DOM analysis (Gemini Vision) for extraction.

## Moderate Severity (Optimization)

### 3. Synchronous Registry Calls in Loops
- **Location:** `src/services/forensics_service.py`
- **Issue:** While the task itself is async, some specialized sub-checks might still block the event loop if not strictly awaited.
- **Fix:** Audit all `httpx` calls to ensure `await` is used consistently across the `gather()` chain.

## Resolved Items (Fixed)

### âœ… Database Session Scope in Background Tasks
- **Fix:** `src/tasks.py` now explicitly initializes a thread-safe session using `with SessionLocal() as db:` inside the Celery worker.

### âœ… Risk Scoring Algorithm
- **Fix:** `RiskEngine` (V2) is implemented (`src/services/risk_engine.py`). It now calculates scores based on Expropriation (Fatal), Act 16 status, and Area discrepancy > 25%.

### âœ… Listing Normalization
- **Fix:** `RealEstateRepository` now normalizes URLs (forcing mobile subdomains) and checks for duplicates before insertion.


=========================================
FILE: ./src/api/routes.py
=========================================
from fastapi import APIRouter, Depends, HTTPException
from sqlalchemy.orm import Session
from src.db.session import get_db
from src.db.models import Listing, Report, ReportStatus
from src.services.repository import RealEstateRepository
from src.tasks import audit_listing_task
from pydantic import BaseModel
from typing import Optional

router = APIRouter()

class AuditRequest(BaseModel):
    url: str
    price_override: float = 0.0

class ReportUpdate(BaseModel):
    status: str
    manual_notes: Optional[str] = None

@router.post("/audit")
async def initiate_audit(request: AuditRequest, db: Session = Depends(get_db)):
    """
    Submits a URL for auditing via the Celery Worker queue.
    """
    repo = RealEstateRepository(db)
    # Create listing immediately to return ID
    listing = repo.create_listing(url=request.url, price=request.price_override, area=0.0, desc="Queued")
    
    # Offload to Redis/Celery
    audit_listing_task.delay(listing.id)
    
    return {"listing_id": listing.id, "status": "QUEUED_IN_REDIS"}

@router.get("/reports/{listing_id}")
def get_report(listing_id: int, db: Session = Depends(get_db)):
    """
    Retrieves the report status and details for a listing.
    """
    listing = db.query(Listing).filter(Listing.id == listing_id).first()
    if not listing:
        raise HTTPException(status_code=404, detail="Listing not found")
        
    report = db.query(Report).filter(Report.listing_id == listing_id).first()
    if not report:
        # If no report exists yet, the worker is likely still processing
        return {"status": "PROCESSING", "details": "Audit is currently in the queue."}
        
    return {
        "report_id": report.id,
        "status": report.status,
        "risk_score": report.risk_score,
        "ai_confidence": report.ai_confidence_score,
        "discrepancies": report.discrepancy_details,
        "manual_notes": report.manual_review_notes,
        "cost": report.cost_to_generate,
        "created_at": report.created_at
    }

@router.patch("/reports/{report_id}")
def update_report_status(report_id: int, update: ReportUpdate, db: Session = Depends(get_db)):
    """
    Manual Review Action.
    Updates status (e.g., MANUAL_REVIEW -> VERIFIED).
    """
    report = db.query(Report).filter(Report.id == report_id).first()
    if not report:
        raise HTTPException(status_code=404, detail="Report not found")
        
    try:
        # Validate that the string provided matches the Enum
        new_status = ReportStatus(update.status)
    except ValueError:
        raise HTTPException(status_code=400, detail="Invalid Status Enum")

    report.status = new_status
    if update.manual_notes:
        report.manual_review_notes = update.manual_notes
        
    db.commit()
    return {"id": report.id, "new_status": report.status}


=========================================
FILE: ./src/core/config.py
=========================================
import os
from pydantic_settings import BaseSettings
from pydantic import Field

class Settings(BaseSettings):
    PROJECT_NAME: str = "Glashaus"
    VERSION: str = "1.0.0-PROD"
    ENV: str = Field("DEV", description="DEV or PROD")
    
    # SECURITY FIX: No default value. Fails safely if missing.
    GEMINI_API_KEY: str = Field(..., min_length=10, description="Must be set in .env")
    
    # Database
    POSTGRES_USER: str = Field(..., min_length=1)
    POSTGRES_PASSWORD: str = Field(..., min_length=1)
    POSTGRES_SERVER: str = Field(..., min_length=1)
    POSTGRES_DB: str = "glashaus_db"
    
    REDIS_URL: str = Field(..., min_length=1)

    @property
    def DATABASE_URL(self) -> str:
        return f"postgresql://{self.POSTGRES_USER}:{self.POSTGRES_PASSWORD}@{self.POSTGRES_SERVER}/{self.POSTGRES_DB}"

    class Config:
        env_file = ".env"
        case_sensitive = True

settings = Settings()


=========================================
FILE: ./src/core/utils.py
=========================================
import re
import hashlib
from urllib.parse import urlparse

def extract_imot_id(url: str) -> str:
    """Extracts unique listing ID to prevent duplicates."""
    match = re.search(r'(?:adv=|obiava-)([a-z0-9]+)', url)
    return match.group(1) if match else "unknown"

def normalize_url(url: str) -> str:
    """Force mobile subdomain to reduce WAF friction."""
    if "imot.bg" in url:
        return url.replace("www.imot.bg", "m.imot.bg")
    return url

def calculate_content_hash(text: str, price: float) -> str:
    clean_text = re.sub(r'\s+', ' ', text).strip().lower()
    raw = f"{clean_text}{price}".encode('utf-8')
    return hashlib.sha256(raw).hexdigest()


=========================================
FILE: ./src/core/sofia_data.py
=========================================
SOFIA_ADMIN_MAP = {
    "OBORISHTE": {"strictness": 5, "kindergarten_risk": "Critical"},
    "PODUYANE": {"strictness": 5, "kindergarten_risk": "High"},
    "CENTER": {"strictness": 4, "kindergarten_risk": "High"},
    "LOZENETS": {"strictness": 4, "kindergarten_risk": "Moderate"},
    "VITOSHA": {"strictness": 2, "kindergarten_risk": "Low"},
    "KRUSTOVA VADA": {"strictness": 2, "kindergarten_risk": "Low"},
}


=========================================
FILE: ./src/core/logger.py
=========================================
import structlog
import logging
import sys

def setup_logging():
    # Standard lib logging for libs that don't use structlog
    logging.basicConfig(format="%(message)s", stream=sys.stdout, level=logging.INFO)
    
    structlog.configure(
        processors=[
            structlog.contextvars.merge_contextvars,
            structlog.processors.add_log_level,
            structlog.processors.TimeStamper(fmt="iso"),
            structlog.processors.JSONRenderer()
        ],
        logger_factory=structlog.stdlib.LoggerFactory(),
        wrapper_class=structlog.stdlib.BoundLogger,
        cache_logger_on_first_use=True,
    )

# Singleton logger instance
logger = structlog.get_logger()


=========================================
FILE: ./src/core/patterns.py
=========================================
import re
from typing import List

class ForensicPatterns:
    """
    Centralized regex registry for text analysis.
    """
    
    VAT_EXCLUDED = re.compile(r"(?i)(Ñ†ÐµÐ½Ð°Ñ‚Ð° Ðµ Ð±ÐµÐ· Ð´Ð´Ñ|Ð±ÐµÐ· Ð´Ð´Ñ|vat excluded|no vat|Ð½Ðµ ÑÐµ Ð½Ð°Ñ‡Ð¸ÑÐ»ÑÐ²Ð° Ð´Ð´Ñ)")
    SPACE_HACK = re.compile(r"(?i)(Ð¿Ñ€ÐµÑƒÑÑ‚Ñ€Ð¾ÐµÐ½Ð°? Ð³Ð°Ñ€ÑÐ¾Ð½Ð¸ÐµÑ€Ð°|ÑƒÑÐ²Ð¾ÐµÐ½.*?Ð±Ð°Ð»ÐºÐ¾Ð½|ÐºÑƒÑ…Ð½Ñ.*?ÐºÐ¾Ñ€Ð¸Ð´Ð¾Ñ€|Ð±Ð¸Ð²ÑˆÐ°.*?ÐºÑƒÑ…Ð½Ñ|Ð¼Ð°Ð»Ð¾Ð¼ÐµÑ€ÐµÐ½|Ð±Ð¾ÐºÑÐ¾Ð½Ð¸ÐµÑ€Ð°|Ñ‚Ð°Ð²Ð°Ð½ÑÐºÐ¾)")
    ATELIER_STATUTE = re.compile(r"(?i)(ÑÑ‚Ð°Ñ‚ÑƒÑ‚.*?Ð°Ñ‚ÐµÐ»Ð¸Ðµ|ÑÑ‚Ð°Ñ‚ÑƒÑ‚ Ð½Ð° Ð°Ñ‚ÐµÐ»Ð¸Ðµ|ÑÑ‚ÑƒÐ´Ð¸Ð¾|Ñ‚Ð²Ð¾Ñ€Ñ‡ÐµÑÐºÐ¾ Ð°Ñ‚ÐµÐ»Ð¸Ðµ|atelier)")
    GROUND_FLOOR = re.compile(r"(?i)(Ð¿Ð°Ñ€Ñ‚ÐµÑ€|ÐµÑ‚Ð°Ð¶ 1 Ð¾Ñ‚|Ð²Ð¸ÑÐ¾Ðº Ð¿Ð°Ñ€Ñ‚ÐµÑ€|ÐºÐ¾Ñ‚Ð° 0|ÑÑƒÑ‚ÐµÑ€ÐµÐ½)")
    FUTURE_COMPLETION = re.compile(r"(?i)(\d{1,2}%.*?ÑÐµÐ³Ð°|\d{1,2}%.*?Ð¿Ñ€ÐµÐ´Ð²Ð°Ñ€Ð¸Ñ‚ÐµÐ»ÐµÐ½|\d{1,2}%.*?Ð°ÐºÑ‚ 16)")

    @classmethod
    def normalize_text(cls, text: str) -> str:
        """Standardize text to catch edge cases."""
        if not text: return ""
        return re.sub(r'\s+', ' ', text).strip().upper()

    @classmethod
    def extract_flags(cls, text: str) -> List[str]:
        flags = []
        if not text: return flags
        
        if cls.VAT_EXCLUDED.search(text):
            flags.append("VAT_EXCLUDED")
        if cls.SPACE_HACK.search(text):
            flags.append("CONVERSION_RISK")
        if cls.ATELIER_STATUTE.search(text):
            flags.append("ATELIER_DETECTED")
        if cls.GROUND_FLOOR.search(text):
            flags.append("GROUND_FLOOR_RISK")
            
        return flags


=========================================
FILE: ./src/services/ai_engine.py
=========================================
import google.generativeai as genai
from pydantic import BaseModel, Field
from typing import List, Optional
from PIL import Image
import os
from src.core.logger import logger

class AIAnalysisSchema(BaseModel):
    address_prediction: str = Field(description="Predicted address or neighborhood based on text/visual landmarks")
    neighborhood: str
    is_atelier: bool = Field(description="True if building style or text suggests non-residential status")
    net_living_area: float
    construction_year: int
    building_type: str = Field(description="Panel, Brick, EPC, or New Construction")
    confidence: int
    visual_red_flags: List[str] = Field(default=[], description="Physical discrepancies like windowless kitchens or office-style windows")

class GeminiService:
    def __init__(self, api_key: str):
        if api_key != "mock-key":
            genai.configure(api_key=api_key)
            # Upgrading to 1.5-flash which supports high-volume vision for low cost
            self.model = genai.GenerativeModel('gemini-1.5-flash')
        else:
            self.model = None

    async def analyze_listing_multimodal(self, text: str, image_paths: List[str]) -> dict:
        """
        Implements the Vision AI forensics suggested by Google Cloud.
        Combines raw text with visual evidence from archived listing photos.
        """
        if not self.model:
            return {
                "address_prediction": "Simulated", 
                "confidence": 0, 
                "neighborhood": "Unknown", 
                "is_atelier": False, 
                "net_living_area": 0, 
                "construction_year": 2024,
                "building_type": "Unknown"
            }
        
        # Load and validate images for the Vision API
        visual_inputs = []
        for path in image_paths[:5]: # Use top 5 images to optimize tokens
            if os.path.exists(path):
                try:
                    visual_inputs.append(Image.open(path))
                except Exception as e:
                    logger.warning("image_load_failed", path=path, error=str(e))

        prompt = f"""
        [ROLE] SENIOR REAL ESTATE FORENSIC DETECTIVE (SOFIA, BULGARIA)
        [OBJECTIVE] Extract ground truth from these photos and the listing text.
        
        [TASKS]
        1. Compare visual building style with the described neighborhood (e.g. Panel in Lozenets?).
        2. Inspect 'Atelier' signs: office-style glass, lack of balconies, or commercial ground floors.
        3. Detect 'Space Hacks': kitchens in hallways, beds in windowless rooms.
        4. Look for landmarks/shop signs in the background to pin-point the address.
        
        [LISTING TEXT]
        {text[:4000]}
        """
        
        # Merge text and images into a single multimodal request
        content = [prompt] + visual_inputs
        
        try:
            resp = self.model.generate_content(
                content, 
                generation_config={
                    "response_mime_type": "application/json", 
                    "response_json_schema": AIAnalysisSchema.model_json_schema()
                }
            )
            return AIAnalysisSchema.model_validate_json(resp.text).model_dump()
        except Exception as e:
            logger.error("ai_multimodal_failed", error=str(e))
            # Fallback to a basic structure
            return {"address_prediction": "Error", "neighborhood": "Unknown", "confidence": 0}



=========================================
FILE: ./src/services/repository.py
=========================================
from decimal import Decimal
from sqlalchemy.orm import Session
from src.db.models import Listing, PriceHistory
from src.core.utils import normalize_url

class RealEstateRepository:
    def __init__(self, db: Session):
        self.db = db

    def create_listing_initial(self, url: str) -> Listing:
        clean_url = normalize_url(url)
        existing = self.db.query(Listing).filter(Listing.source_url == clean_url).first()
        if existing: return existing
        new_l = Listing(source_url=clean_url)
        self.db.add(new_l)
        self.db.commit()
        self.db.refresh(new_l)
        return new_l

    # TYPE SAFETY FIX: price is now Decimal
    def update_listing_data(self, listing_id: int, price: Decimal, area: float, desc: str, chash: str):
        listing = self.db.query(Listing).get(listing_id)
        if listing:
            # SQLAlchemy handles Decimal comparison correctly here
            if listing.price_bgn is not None and listing.price_bgn != price:
                history = PriceHistory(listing_id=listing_id, price_bgn=listing.price_bgn)
                self.db.add(history)
            
            listing.price_bgn = price
            listing.advertised_area_sqm = area
            listing.description_raw = desc
            listing.content_hash = chash
            self.db.commit()


=========================================
FILE: ./src/services/scraper_mvp.py
=========================================
from bs4 import BeautifulSoup
import os

# CONFIG
SIMULATION_MODE = True
MOCK_FILE = "imot_simulation.html"

def run_recon():
    print("[*] INTEL: Starting Reconnaissance Protocol...")
    
    html_content = ""
    
    if SIMULATION_MODE:
        print(f"[*] MODE: SIMULATION (Bypassing WAF)")
        if not os.path.exists(MOCK_FILE):
            print(f"[!] Error: Mock file {MOCK_FILE} not found.")
            return
            
        with open(MOCK_FILE, "r", encoding="utf-8") as f:
            html_content = f.read()
    else:
        # Network logic removed for Termux Safety
        pass

    soup = BeautifulSoup(html_content, 'html.parser')
    links = soup.find_all('a', href=True)
    
    print("[*] Parsing DOM Structure...")
    
    count = 0
    listings_found = []
    
    for link in links:
        href = link['href']
        
        if 'act=5' in href:
            # Normalize URL
            full_url = "https:" + href if href.startswith("//") else href
            
            if full_url in listings_found:
                continue
                
            listings_found.append(full_url)
            text_content = link.get_text(separator=" ", strip=True)
            
            count += 1
            print(f"\n[TARGET #{count}]")
            print(f"   URL: {full_url}")
            print(f"   RAW: {text_content}")

    print(f"\n[*] Mission Complete. {count} mock targets extracted.")

if __name__ == "__main__":
    run_recon()


=========================================
FILE: ./src/services/scraper_service.py
=========================================
import httpx
import re
import asyncio
from decimal import Decimal, InvalidOperation
from bs4 import BeautifulSoup
from playwright.async_api import async_playwright
from src.schemas import ScrapedListing
from src.core.logger import logger

class WAFBlockError(Exception): pass

class ScraperService:
    def __init__(self, client: httpx.AsyncClient, simulation_mode=False):
        self.client = client
        self.simulation = simulation_mode
        self.headers = {
            "User-Agent": "Mozilla/5.0 (iPhone; CPU iPhone OS 17_0 like Mac OS X) AppleWebKit/605.1.15 Mobile Safari/604.1",
            "Accept-Language": "bg-BG,bg;q=0.9"
        }

    async def scrape_url(self, url: str) -> ScrapedListing:
        clean_url = url.replace("www.imot.bg", "m.imot.bg")
        log = logger.bind(url=clean_url)
        
        try:
            # 1. Try Fast Path (HTTPX)
            return await self._scrape_fast(clean_url, log)
            
        except WAFBlockError:
            log.warning("waf_intercept_detected", strategy="switching_to_headless_browser")
            # 2. Fallback to Heavy Path (Playwright)
            return await self._scrape_heavy_browser(clean_url, log)

        except Exception as e:
            log.error("scrape_failed_fatal", error=str(e))
            raise e

    async def _scrape_fast(self, url: str, log) -> ScrapedListing:
        resp = await self.client.get(url, headers=self.headers, follow_redirects=True)
        content = resp.content.decode('windows-1251', errors='ignore')

        if any(x in content.lower() for x in ["captcha", "security check", "verify you are human"]):
            raise WAFBlockError("Fast scrape blocked")
            
        log.info("scrape_success_fast")
        return await asyncio.to_thread(self._parse_html, content, url)

    async def _scrape_heavy_browser(self, url: str, log) -> ScrapedListing:
        """Launches a headless browser to execute JS challenges."""
        async with async_playwright() as p:
            browser = await p.firefox.launch(headless=True)
            context = await browser.new_context(
                user_agent=self.headers["User-Agent"],
                viewport={"width": 390, "height": 844}
            )
            page = await context.new_page()
            
            try:
                await page.goto(url, wait_until="domcontentloaded")
                
                # Wait for WAF to clear or price to appear (Max 10s)
                try:
                    await page.wait_for_selector('div#price, .price, .advHeader', timeout=10000)
                except Exception:
                    log.warning("browser_wait_timeout_proceeding_anyway")
                
                content = await page.content()
                log.info("scrape_success_heavy")
                return await asyncio.to_thread(self._parse_html, content, url)
                
            finally:
                await browser.close()

    def _parse_html(self, content: str, url: str) -> ScrapedListing:
        soup = BeautifulSoup(content, 'html.parser')
        text = soup.get_text(" ", strip=True)

        # Price Parsing
        p_match = re.search(r'([\d\s\.,]+)\s?(?:EUR|â‚¬|Ð»Ð²)', text)
        price_decimal = Decimal("0.00")
        if p_match:
            try:
                clean_str = re.sub(r'[^\d]', '', p_match.group(1))
                price_decimal = Decimal(clean_str)
            except InvalidOperation:
                logger.warning("price_parse_failed", url=url)

        # Area Parsing
        a_match = re.search(r'(\d+)\s?(?:kv|ÐºÐ²)', text.lower())
        area = Decimal(a_match.group(1)) if a_match else Decimal("0.00")
        
        images = [img.get('src') for img in soup.find_all('img') if 'imot.bg' in (img.get('src') or "")]

        return ScrapedListing(
            source_url=url,
            raw_text=text,
            price_predicted=price_decimal,
            area_sqm=area,
            image_urls=images
        )


=========================================
FILE: ./src/services/risk_engine.py
=========================================
from typing import Dict, Any

class RiskEngine:
    def calculate_score_v2(self, data: Dict) -> Dict[str, Any]:
        """
        Consolidated Risk Calculation using all 3 sources.
        """
        score = 0
        flags = []
        is_fatal = False
        
        ai = data.get("ai", {})
        cad = data.get("cadastre") or {}
        comp = data.get("compliance", {})
        risk = data.get("city_risk", {})
        
        # 1. EXPROPRIATION (The Nuke)
        if risk.get("is_expropriated"):
            score = 100
            is_fatal = True
            flags.append("CRITICAL: Property is listed for EXPROPRIATION (Seizure).")

        # 2. ACT 16 (The Ghost)
        # Only penalize if we actually checked and found nothing, and building year implies we should have it
        if comp.get("checked") and not comp.get("has_act16"):
            # If AI says it's old (pre-2000), missing record might just mean digitization lag.
            # If AI says it's new (post-2010), missing record is suspicious.
            year = ai.get("construction_year", 0)
            if year > 2010:
                score += 50
                flags.append("HIGH RISK: No Commissioning Certificate (Act 16) found for modern building.")
            else:
                score += 10
                flags.append("WARN: Act 16 not digitized or missing.")

        # 3. AREA FRAUD (The Squeeze)
        adv_area = data["scraped"].get("area", 0)
        off_area = cad.get("official_area", 0)
        
        if adv_area > 0 and off_area > 0:
            diff_ratio = (adv_area - off_area) / off_area
            if diff_ratio > 0.25: # >25% discrepancy
                score += 30
                flags.append(f"SCAM: Advertised area {adv_area}m is {diff_ratio:.1%} larger than Official {off_area}m.")
        
        # 4. LEGAL / ATELIER
        if ai.get("is_atelier", False):
            score += 25
            flags.append("LEGAL: Atelier status (Non-residential).")

        final_score = 100 if is_fatal else min(score, 100)
        return {"score": final_score, "flags": flags, "is_fatal": is_fatal}

    # Legacy V1 (Keep for backward compat if needed)
    def calculate_score(self, advertised, ai, cadastre_area=None):
        return self.calculate_score_v2({"scraped": advertised, "ai": ai, "cadastre": {"official_area": cadastre_area}})


=========================================
FILE: ./src/services/cadastre_service.py
=========================================
import asyncio
import re
import httpx
from bs4 import BeautifulSoup
from src.schemas import CadastreData

class CadastreService:
    """Registry Forensics: human address -> Official registry truth."""
    
    def __init__(self, client: httpx.AsyncClient):
        self.client = client
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:142.0) Gecko/142.0',
            'X-Requested-With': 'XMLHttpRequest',
            'Referer': 'https://kais.cadastre.bg/bg/Map'
        }

    async def get_official_details(self, address: str) -> CadastreData:
        try:
            # Handshake 1: CSRF
            resp = await self.client.get("https://kais.cadastre.bg/bg/Map", headers=self.headers)
            soup = BeautifulSoup(resp.text, 'html.parser')
            token_tag = soup.find('input', {'name': '__RequestVerificationToken'})
            
            if not token_tag:
                return CadastreData(status="ERROR", official_area=0.0)
                
            token = token_tag.get('value')
            
            # Handshake 2: Strike
            await self.client.get("https://kais.cadastre.bg/bg/Map/FastSearch", 
                                  params={'KeyWords': address}, headers=self.headers)
            await asyncio.sleep(0.6) # Compliance Delay
            
            # Handshake 3: Read
            read_headers = {**self.headers, 'X-CSRF-TOKEN': token}
            res = await self.client.post("https://kais.cadastre.bg/bg/Map/ReadFoundObjects", 
                                   data={'page': 1, 'pageSize': 5}, headers=read_headers)
            data = res.json()
            
            if not data.get('Data'): 
                return CadastreData(status="NOT_FOUND", official_area=0.0)

            # Handshake 4: Detail Parse
            obj = data['Data'][0]
            info = await self.client.get("https://kais.cadastre.bg/bg/Map/GetObjectInfo", 
                                         params=obj, headers=self.headers)
            
            # Handshake 5: Regex extraction
            area_match = re.search(r"Ð¿Ð»Ð¾Ñ‰(?: Ð¿Ð¾ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚)?\s*([\d\.]+)\s*ÐºÐ²\.Ð¼", info.text)
            area = float(area_match.group(1)) if area_match else 0.0
            
            return CadastreData(
                cadastre_id=obj.get('Number'),
                official_area=area,
                address_found=obj.get('Address'),
                status="LIVE"
            )
        except Exception as e:
            return CadastreData(status="ERROR", official_area=0.0)


=========================================
FILE: ./src/services/geospatial_service.py
=========================================
from typing import Optional, Dict

class GeospatialService:
    """
    Handles Google Maps / Street View verification.
    """
    def __init__(self, api_key: str = "mock-key"):
        self.api_key = api_key

    def verify_location(self, address: str) -> Dict[str, any]:
        """
        TODO: Implement Google Maps Geocoding API.
        Should return { "lat": float, "lng": float, "street_view_exists": bool }
        """
        if self.api_key == "mock-key":
            return {"lat": 42.6977, "lng": 23.3219, "verified": False}
        
        # Real implementation will go here
        return {}


=========================================
FILE: ./src/services/base_provider.py
=========================================
from abc import ABC, abstractmethod
from typing import Optional, Dict, Any

class BaseRegistryProvider(ABC):
    @abstractmethod
    def fetch_details(self, address: str) -> Optional[Dict[str, Any]]:
        """Fetch official property data from a government registry."""
        pass

class BaseGeoProvider(ABC):
    @abstractmethod
    def geocode(self, address: str) -> Dict[str, Any]:
        """Convert address to GPS coordinates."""
        pass


=========================================
FILE: ./src/services/storage_service.py
=========================================
import os
import httpx
import asyncio
from typing import List

class StorageService:
    def __init__(self, upload_dir="storage/archive"):
        self.upload_dir = upload_dir
        os.makedirs(upload_dir, exist_ok=True)

    async def _download_single(self, client: httpx.AsyncClient, url: str, filename: str) -> str:
        try:
            resp = await client.get(url, timeout=7.0)
            if resp.status_code == 200:
                path = os.path.join(self.upload_dir, filename)
                with open(path, "wb") as f:
                    f.write(resp.content)
                return path
        except Exception as e:
            print(f"Archive Fail: {url} -> {e}")
        return None

    async def archive_images(self, listing_id: int, urls: List[str]) -> List[str]:
        if not urls: return []
        async with httpx.AsyncClient() as client:
            tasks = []
            for i, url in enumerate(urls):
                filename = f"listing_{listing_id}_{i}.jpg"
                tasks.append(self._download_single(client, url, filename))
            results = await asyncio.gather(*tasks)
            return [r for r in results if r is not None]


=========================================
FILE: ./src/services/legal_engine.py
=========================================
from src.core.sofia_data import SOFIA_ADMIN_MAP
from src.core.patterns import ForensicPatterns  # Import the new patterns
from datetime import datetime

class LegalEngine:
    def analyze_listing(self, scraped_data: dict, ai_data: dict):
        risk_report = {
            "total_legal_score": 0,
            "pillars": {},
            "gatekeeper_verdict": "CLEAR",
            "flags": []
        }

        raw_text = scraped_data.get("raw_text", "").upper()
        
        # 0. REGEX FORENSICS (New Layer)
        regex_flags = ForensicPatterns.extract_flags(raw_text)
        risk_report["flags"].extend(regex_flags)
        
        # Apply score penalties for regex flags
        if "VAT_EXCLUDED" in regex_flags:
            risk_report["flags"].append("FINANCIAL: Advertised price is likely 20% higher (+VAT).")
        if "CONVERSION_RISK" in regex_flags:
             risk_report["total_legal_score"] += 30
             risk_report["flags"].append("PHYSICAL: High risk of 'Space Hack' (Garage/Corridor conversion).")

        # Pillar I: Statutory Classification (The Atelier Trap)
        p1_score = 0
        if ai_data.get("is_atelier") or "ÐÐ¢Ð•Ð›Ð˜Ð•" in raw_text or "ATELIER" in raw_text:
            p1_score += 35 
            if any(x in raw_text for x in ["Ð¡Ð•Ð’Ð•Ð ", "NORTH"]):
                p1_score += 15
                risk_report["flags"].append("INSOLENCE_FAILURE: North-facing Atelier cannot legally be an apartment.")
            
            rayon = ai_data.get("neighborhood", "Unknown").upper()
            admin_data = SOFIA_ADMIN_MAP.get(rayon, {"strictness": 3})
            if admin_data["strictness"] >= 4:
                p1_score += 20
                risk_report["flags"].append(f"ADDRESS_REG_RISK: District {rayon} is notoriously strict for Atelier owners.")

        risk_report["pillars"]["classification"] = p1_score

        # Pillar II: Construction Purgatory (The 'Akt' Matrix)
        p2_score = 0
        current_year = datetime.now().year
        if "ÐÐšÐ¢ 15" in raw_text or "ACT 15" in raw_text:
            build_year = ai_data.get("construction_year")
            if build_year and (current_year - build_year) > 2:
                p2_score += 45
                risk_report["flags"].append("ETERNAL_AKT_15: Building lacks Akt 16 for over 24 months.")
        risk_report["pillars"]["construction"] = p2_score

        # Pillar III: Area Value Integrity (Common Parts Ratio)
        p3_score = 0
        total_area = scraped_data.get("area", 0)
        net_area = ai_data.get("net_living_area", 0)
        if total_area > 0 and net_area > 0:
            ratio = (total_area - net_area) / total_area
            if ratio > 0.25:
                p3_score += 40
                risk_report["flags"].append(f"PREDATORY_COMMON_PARTS: {ratio:.1%} is non-living space.")
        risk_report["pillars"]["area_value"] = p3_score

        # Pillar IV: High-Yield Legal Encumbrances (Toxicity Rank)
        toxicity_score = 0
        if any(x in raw_text for x in ["ÐŸÐžÐ›Ð—Ð’ÐÐÐ•", "ÐŸÐžÐ–Ð˜Ð—ÐÐ•ÐÐž", "USER RIGHT"]):
            toxicity_score = 100
            risk_report["gatekeeper_verdict"] = "ABORT"
            risk_report["flags"].append("FATAL: RIGHT OF USE (Nude Ownership).")
        
        if any(x in raw_text for x in ["Ð˜Ð¡ÐšÐžÐ’Ð ÐœÐžÐ›Ð‘Ð", "Ð¡ÐªÐ”Ð•Ð‘Ð•Ð", "LITIGATION", "CLAIM"]):
            toxicity_score = max(toxicity_score, 95)
            risk_report["gatekeeper_verdict"] = "ABORT"
            risk_report["flags"].append("FATAL: PENDING LITIGATION (Iskova Molba).")

        if any(x in raw_text for x in ["Ð’ÐªÐ—Ð‘Ð ÐÐÐ", "Ð§Ð¡Ð˜", "ÐÐÐŸ", "DISTRAINT"]):
            toxicity_score = max(toxicity_score, 90)
            risk_report["flags"].append("CRITICAL: DISTRAINT (Asset Frozen for Debt).")

        risk_report["pillars"]["toxicity"] = toxicity_score
        risk_report["total_legal_score"] = max(p1_score, p2_score, p3_score, toxicity_score)
        
        return risk_report


=========================================
FILE: ./src/services/report_generator.py
=========================================
import datetime

class AttorneyReportGenerator:
    """
    Transforms quantitative risk data and forensic evidence into a senior legal brief.
    Now includes Registry Checks (Act 16, Expropriation) and Cadastre Verification.
    """
    def generate_legal_brief(self, listing_data: dict, risk_data: dict, ai_data: dict) -> str:
        # risk_data is now a merged dictionary of {**legal_res, **score_res, "forensics": ...}
        
        score = risk_data.get("score", 0) # V2 Score
        flags = risk_data.get("flags", [])
        forensics = risk_data.get("forensics", {})
        
        compliance = forensics.get("compliance", {})
        city_risk = forensics.get("city_risk", {})
        cadastre = forensics.get("cadastre", {})

        # 1. Determine Header Status
        status_symbol = "ðŸŸ¢ CLEAR"
        if risk_data.get("is_fatal") or "ABORT" in risk_data.get("gatekeeper_verdict", ""):
            status_symbol = "ðŸ”´ DO NOT PROCEED"
        elif score > 60:
            status_symbol = "ðŸŸ  HIGH RISK ASSET"
        elif score > 30:
            status_symbol = "ðŸŸ¡ CAUTION ADVISED"

        # 2. Build Sections
        sections = [
            f"# {status_symbol} (Risk Score: {score}/100)",
            f"**Generated:** {datetime.datetime.now().strftime('%Y-%m-%d %H:%M')}",
            "\n## I. Executive Summary",
            self._summary(risk_data, city_risk),
            "\n## II. Registry & Compliance Checks",
            self._compliance_section(compliance, city_risk),
            "\n## III. Cadastral Integrity",
            self._cadastre_section(listing_data, cadastre),
            "\n## IV. Legal & Statutory Risks",
            self._legal_section(ai_data, risk_data),
            "\n## V. Identified Risk Factors",
            "\n".join([f"- {f}" for f in flags]) if flags else "- No specific flags raised."
        ]
        
        return "\n".join(sections)

    def _summary(self, risk, city_risk):
        if city_risk.get("is_expropriated"):
            return "**CRITICAL WARNING:** This property is flagged for EXPROPRIATION (Municipal Seizure). Immediate suspension of interest recommended."
        if risk.get("is_fatal"):
            return "Fatal legal defects detected. The asset is legally toxic."
        if risk.get("score", 0) > 50:
            return "Significant administrative or physical discrepancies detected. Negotiating power is high, but so is future friction."
        return "The asset appears to align with standard Sofia residential norms. Proceed to physical inspection."

    def _compliance_section(self, compliance, city_risk):
        # 1. Expropriation
        expr_status = "âœ… CLEAR"
        if city_risk.get("is_expropriated"): expr_status = "ðŸ”´ **EXPROPRIATION RISK DETECTED**"
        elif city_risk.get("registry_status") == "OFFLINE": expr_status = "âšª CHECK FAILED (Registry Offline)"
        
        # 2. Act 16
        act16_status = "â“ UNKNOWN"
        if compliance.get("checked"):
            if compliance.get("has_act16"): act16_status = "âœ… YES (Certificate Found)"
            else: act16_status = "âš ï¸ **MISSING/NOT DIGITIZED**"
        
        if compliance.get("registry_status") == "OFFLINE":
            act16_status = "âšª CHECK FAILED (Registry Offline)"

        return f"""
- **Municipal Expropriation List:** {expr_status}
- **Commissioning Certificate (Act 16):** {act16_status}
        """

    def _cadastre_section(self, listing, cadastre):
        status = cadastre.get("registry_status", "LIVE")
        if status == "OFFLINE":
            return "- **Status:** âšª Registry Offline. Cannot verify area."
        
        official_area = cadastre.get("official_area", 0)
        adv_area = listing.get("area", 0)
        
        if official_area == 0:
            return f"- **Status:** âš ï¸ No matching object found in Cadastre for address."
            
        diff = adv_area - official_area
        percent = (diff / official_area) * 100 if official_area > 0 else 0
        
        verdict = "âœ… Matches"
        if percent > 20: verdict = "ðŸ”´ **SIGNIFICANT INFLATION**"
        elif percent > 10: verdict = "ðŸŸ¡ Moderate Discrepancy"
        
        return f"""
- **Official Cadastre Area:** {official_area} sq.m
- **Advertised Area:** {adv_area} sq.m
- **Discrepancy:** {diff:+.1f} sq.m ({percent:+.1f}%) -> {verdict}
- **Cadastre ID:** {cadastre.get("cadastre_id", "Unknown")}
        """

    def _legal_section(self, ai, risk):
        # Merge the old "Legal Engine" text here
        text = []
        if ai.get("is_atelier"):
            text.append("- **Classification:** âš ï¸ ATELIER (Not a legal apartment). Issues with address registration expected.")
        else:
            text.append("- **Classification:** âœ… Residential Apartment.")
            
        if "construction" in risk.get("pillars", {}):
            score = risk["pillars"]["construction"]
            if score > 0: text.append(f"- **Construction Maturity:** âš ï¸ Potential 'Eternal Act 15' risk detected.")
            
        return "\n".join(text)


=========================================
FILE: ./src/services/compliance_service.py
=========================================
import httpx
import uuid
from src.core.logger import logger

class ComplianceService:
    BASE_URL = 'https://nag.sofia.bg/RegisterCertificateForExploitationBuildings'
    
    def __init__(self, client: httpx.AsyncClient = None):
        self.client = client

    async def check_act_16(self, cadastre_id: str) -> dict:
        log = logger.bind(cadastre_id=cadastre_id)
        if not cadastre_id: 
            return {"has_act16": False, "checked": False}

        # Use injected client (preferred) or create ephemeral one
        # REMOVED verify=False. Production requires valid SSL or mounted CAs.
        local_client = self.client if self.client else httpx.AsyncClient(timeout=10.0)
        
        try:
            search_params = {'searchQueryId': str(uuid.uuid4()), 'Identifier': cadastre_id}
            
            # 1. Search
            await local_client.get(f"{self.BASE_URL}/Search", params=search_params)
            
            # 2. Read
            res = await local_client.post(f"{self.BASE_URL}/Read", data={'page': '1', 'pageSize': '10'})
            res.raise_for_status()
            data = res.json()
            
            has_cert = len(data.get("Data", [])) > 0
            log.info("compliance_check", found=has_cert)
            
            return {
                "has_act16": has_cert, 
                "checked": True,
                "registry_status": "LIVE"
            }

        except (httpx.ConnectError, httpx.TimeoutException, httpx.HTTPStatusError) as e:
            log.warning("registry_down", error=str(e))
            return {"has_act16": False, "checked": False, "registry_status": "OFFLINE"}
            
        finally:
            # Only close if we created it locally
            if not self.client:
                await local_client.aclose()


=========================================
FILE: ./src/services/city_risk_service.py
=========================================
import httpx
from src.core.logger import logger

class CityRiskService:
    BASE_URL = 'https://nag.sofia.bg/RegisterExpropriation'
    HEADERS = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
        'X-Requested-With': 'XMLHttpRequest',
        'Origin': 'https://nag.sofia.bg'
    }

    def __init__(self, client: httpx.AsyncClient = None):
        self.client = client

    async def check_expropriation(self, cadastre_id: str, district: str = "") -> dict:
        log = logger.bind(cadastre_id=cadastre_id)
        if not cadastre_id: return {"is_expropriated": False}

        local_client = self.client if self.client else httpx.AsyncClient(headers=self.HEADERS, timeout=10.0)

        try:
            # 1. Set Context
            await local_client.post(f"{self.BASE_URL}/Search", data={'CadNumber': cadastre_id, 'RegionName': district})
            
            # 2. Fetch
            res = await local_client.post(f"{self.BASE_URL}/Read", data={'page': '1', 'pageSize': '10'})
            res.raise_for_status()
            data = res.json()

            is_risk = data and data.get("Data") and len(data["Data"]) > 0
            
            if is_risk:
                log.critical("expropriation_risk_found", details=str(data["Data"][0]))
                return {
                    "is_expropriated": True, 
                    "details": str(data["Data"][0]),
                    "risk_level": "CRITICAL",
                    "registry_status": "LIVE"
                }
            
            return {"is_expropriated": False, "registry_status": "LIVE"}

        except (httpx.ConnectError, httpx.TimeoutException) as e:
            log.warning("registry_down", error=str(e))
            return {"is_expropriated": False, "registry_status": "OFFLINE"}
        finally:
            if not self.client:
                await local_client.aclose()


=========================================
FILE: ./src/services/forensics_service.py
=========================================
import httpx
import uuid
import time
from src.core.logger import logger

class SofiaMunicipalForensics:
    """Check Act 16 and Construction Permits at nag.sofia.bg."""
    def __init__(self, client: httpx.AsyncClient = None):
        self.headers = {'User-Agent': 'Mozilla/5.0', 'X-Requested-With': 'XMLHttpRequest'}
        self.client = client

    async def run_compliance_check(self, cadastre_id: str) -> dict:
        if not cadastre_id: return {"has_act16": False, "permits": 0}
        
        # Use injected client if available (efficient) or new safe client
        if self.client:
            return await self._execute_check(self.client, cadastre_id)
            
        async with httpx.AsyncClient(headers=self.headers, timeout=15.0) as client:
            return await self._execute_check(client, cadastre_id)

    async def _execute_check(self, client, cadastre_id):
        return {
            "act16": await self._check_act16(client, cadastre_id),
            "permits": await self._check_permits(client, cadastre_id)
        }

    async def _check_act16(self, client, cid):
        try:
            await client.get("https://nag.sofia.bg/RegisterCertificateForExploitationBuildings/Search", 
                            params={'searchQueryId': str(uuid.uuid4()), 'Identifier': cid})
            res = await client.post("https://nag.sofia.bg/RegisterCertificateForExploitationBuildings/Read", 
                                  data={'page': '1', 'pageSize': '10'})
            return len(res.json().get("Data", [])) > 0
        except Exception as e:
            logger.error("forensics_act16_fail", error=str(e))
            return False

    async def _check_permits(self, client, cid):
        try:
            # Emulate browser navigation to set cookies/session
            await client.get("https://nag.sofia.bg/RegisterBuildingPermitsPortal")
            await client.get("https://nag.sofia.bg/RegisterBuildingPermitsPortal/Search", 
                            params={'searchQueryId': str(uuid.uuid4()), 'Identifier': cid, '_': int(time.time()*1000)})
            res = await client.post("https://nag.sofia.bg/RegisterBuildingPermitsPortal/Read", data={'page': 1, 'pageSize': 10})
            return res.json().get("Total", 0)
        except Exception:
            return 0


=========================================
FILE: ./src/__init__.py
=========================================


=========================================
FILE: ./src/main.py
=========================================
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from src.api import routes

app = FastAPI(
    title="Glashaus API",
    description="Automated Real Estate Due Diligence Engine",
    version="1.0.0"
)

# Allow connections from Frontend/Dashboard
origins = [
    "http://localhost",
    "http://localhost:3000",
    "http://localhost:8080",
]

app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

app.include_router(routes.router)

@app.get("/")
def health_check():
    return {
        "system": "GLASHAUS", 
        "status": "OPERATIONAL", 
        "version": "1.0.0-PROD"
    }

if __name__ == "__main__":
    import uvicorn
    uvicorn.run("src.main:app", host="0.0.0.0", port=8000)


=========================================
FILE: ./src/db/session.py
=========================================
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker, declarative_base
from src.core.config import settings

# SQLite requires a specific argument for threading
connect_args = {"check_same_thread": False} if "sqlite" in settings.DATABASE_URL else {}

engine = create_engine(
    settings.DATABASE_URL, 
    connect_args=connect_args,
    pool_pre_ping=True
)

SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)
Base = declarative_base()

def get_db():
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()


=========================================
FILE: ./src/db/models.py
=========================================
import enum
from sqlalchemy import Column, Integer, String, Float, DateTime, Boolean, ForeignKey, JSON, Text, Enum, Numeric
from sqlalchemy.orm import relationship
from sqlalchemy.sql import func
from src.db.session import Base

class ReportStatus(str, enum.Enum):
    PENDING = "PENDING"
    PROCESSING = "PROCESSING"
    VERIFIED = "VERIFIED"
    MANUAL_REVIEW = "MANUAL_REVIEW"
    REJECTED = "REJECTED"

class Listing(Base):
    __tablename__ = "listings"
    id = Column(Integer, primary_key=True, index=True)
    source_url = Column(String, unique=True, nullable=False, index=True)
    content_hash = Column(String(64), index=True)
    
    # Financial Precision
    price_bgn = Column(Numeric(12, 2)) 
    
    # Area Precision (Fixed from Float)
    advertised_area_sqm = Column(Numeric(10, 2))
    
    description_raw = Column(Text)
    scraped_at = Column(DateTime(timezone=True), server_default=func.now())
    
    reports = relationship("Report", back_populates="listing", cascade="all, delete-orphan")
    price_history = relationship("PriceHistory", back_populates="listing")

class Building(Base):
    __tablename__ = "buildings"
    id = Column(Integer, primary_key=True)
    cadastre_id = Column(String, unique=True, index=True)
    address_full = Column(String)
    latitude = Column(Float)
    longitude = Column(Float)
    construction_year = Column(Integer)
    reports = relationship("Report", back_populates="building")

class PriceHistory(Base):
    __tablename__ = "price_history"
    id = Column(Integer, primary_key=True)
    listing_id = Column(Integer, ForeignKey("listings.id"))
    price_bgn = Column(Numeric(12, 2))
    changed_at = Column(DateTime(timezone=True), server_default=func.now())
    listing = relationship("Listing", back_populates="price_history")

class Report(Base):
    __tablename__ = "reports"
    id = Column(Integer, primary_key=True, index=True)
    listing_id = Column(Integer, ForeignKey("listings.id"))
    building_id = Column(Integer, ForeignKey("buildings.id"), nullable=True)
    status = Column(Enum(ReportStatus), default=ReportStatus.PENDING)
    risk_score = Column(Integer)
    ai_confidence_score = Column(Integer, default=0)
    legal_brief = Column(Text)
    discrepancy_details = Column(JSON)
    image_archive_urls = Column(JSON)
    
    cost_to_generate = Column(Numeric(10, 4)) 
    
    manual_review_notes = Column(Text, nullable=True)
    created_at = Column(DateTime(timezone=True), server_default=func.now())
    listing = relationship("Listing", back_populates="reports")
    building = relationship("Building", back_populates="reports")


=========================================
FILE: ./src/worker.py
=========================================
import os
from celery import Celery
from src.core.config import settings

celery_app = Celery(
    "glashaus_worker",
    broker=settings.REDIS_URL,
    backend=settings.REDIS_URL
)

celery_app.conf.update(
    task_serializer="json",
    accept_content=["json"],
    result_serializer="json",
    timezone="Europe/Sofia",
    enable_utc=True,
)

# Auto-discover tasks in src/tasks.py
celery_app.autodiscover_tasks(['src.tasks'])


=========================================
FILE: ./src/tasks.py
=========================================
from asgiref.sync import async_to_sync
from src.worker import celery_app
from src.db.session import SessionLocal
from src.db.models import Listing, Report, ReportStatus
from src.services.scraper_service import ScraperService
from src.services.ai_engine import GeminiService
from src.services.storage_service import StorageService
from src.services.repository import RealEstateRepository
from src.services.cadastre_service import CadastreService
from src.services.compliance_service import ComplianceService
from src.services.city_risk_service import CityRiskService
from src.services.risk_engine import RiskEngine
from src.services.legal_engine import LegalEngine
from src.services.report_generator import AttorneyReportGenerator
from src.core.utils import calculate_content_hash
from src.core.config import settings
from src.schemas import ScrapedListing, AIAnalysisResult, RegistryCheck
from src.core.logger import logger
import asyncio
import httpx

@celery_app.task(name="src.tasks.audit_listing", bind=True, 
                 autoretry_for=(Exception,), 
                 retry_backoff=True, max_retries=3)
def audit_listing_task(self, listing_id: int):
    return async_to_sync(run_audit_pipeline)(listing_id)

async def run_audit_pipeline(listing_id: int):
    log = logger.bind(listing_id=listing_id)
    log.info("audit_started_multimodal")

    async with httpx.AsyncClient(timeout=30.0) as http_client:
        with SessionLocal() as db:
            try:
                # 1. Init Services
                repo = RealEstateRepository(db)
                scraper = ScraperService(client=http_client)
                ai_engine = GeminiService(api_key=settings.GEMINI_API_KEY)
                storage = StorageService()
                risk_engine = RiskEngine()
                legal_engine = LegalEngine()
                brief_gen = AttorneyReportGenerator()

                listing = db.query(Listing).get(listing_id)
                if not listing: return "Error: Listing not found"

                # 2. Scrape Data
                scraped_data: ScrapedListing = await scraper.scrape_url(listing.source_url)
                
                # 3. Archive Images FIRST (to enable Vision AI)
                archived_paths = await storage.archive_images(listing_id, scraped_data.image_urls)
                
                # 4. Multimodal AI Analysis (The "Vision AI" Update)
                ai_raw = await ai_engine.analyze_listing_multimodal(
                    scraped_data.raw_text, 
                    archived_paths
                )
                ai_data = AIAnalysisResult(**ai_raw)

                # 5. Parallel Forensic Registry Striking
                cadastre = CadastreService(client=http_client)
                compliance = ComplianceService(client=http_client)
                city_risk = CityRiskService(client=http_client)

                cad_data, comp_raw, risk_raw = await asyncio.gather(
                    cadastre.get_official_details(ai_data.address_prediction), 
                    compliance.check_act_16(None), # Cadastre ID needed here for real prod
                    city_risk.check_expropriation(None)
                )

                # 6. Final Risk Scoring & Brief Generation
                forensic_dict = {
                    "scraped": scraped_data.model_dump(),
                    "ai": ai_data.model_dump(),
                    "cadastre": cad_data.model_dump(),
                    "compliance": comp_raw,
                    "city_risk": risk_raw
                }
                
                score_res = risk_engine.calculate_score_v2(forensic_dict)
                legal_res = legal_engine.analyze_listing(scraped_data.model_dump(), ai_data.model_dump())
                final_score = max(score_res["score"], legal_res["total_legal_score"])
                
                report = Report(
                    listing_id=listing_id,
                    status=ReportStatus.VERIFIED if final_score < 40 else ReportStatus.MANUAL_REVIEW,
                    risk_score=final_score,
                    ai_confidence_score=ai_data.confidence_score,
                    legal_brief=brief_gen.generate_legal_brief(scraped_data.model_dump(), {**score_res, "forensics": forensic_dict}, ai_data.model_dump()),
                    discrepancy_details=forensic_dict,
                    image_archive_urls=archived_paths
                )
                db.add(report)
                db.commit()
                
                return f"Audit Complete: Score {final_score}"

            except Exception as exc:
                db.rollback()
                log.exception("audit_pipeline_failed")
                raise exc


=========================================
FILE: ./src/schemas.py
=========================================
from pydantic import BaseModel, Field, condecimal
from decimal import Decimal
from typing import List, Optional, Literal

class ScrapedListing(BaseModel):
    source_url: str
    raw_text: str
    price_predicted: condecimal(max_digits=12, decimal_places=2) 
    
    # PRECISION FIX: Area is now strictly Decimal
    area_sqm: condecimal(max_digits=10, decimal_places=2)
    
    image_urls: List[str] = []
    
    class Config:
        json_encoders = {Decimal: str}

class AIAnalysisResult(BaseModel):
    address_prediction: str
    neighborhood: str
    is_atelier: bool
    net_living_area: float
    construction_year: int
    confidence_score: int = Field(default=0, ge=0, le=100)

class RegistryCheck(BaseModel):
    registry_status: Literal["LIVE", "OFFLINE", "ERROR"] = "LIVE"
    details: str = ""
    is_risk_detected: bool = False
    checked: bool = False

class CadastreData(BaseModel):
    official_area: float = 0.0
    cadastre_id: Optional[str] = None
    status: Literal["LIVE", "OFFLINE", "NOT_FOUND", "ERROR"] = "NOT_FOUND"
    address_found: Optional[str] = None


=========================================
FILE: ./scripts/context_dump.sh
=========================================
#!/bin/bash
# Scans the repo and dumps text files for LLM context
output="glashaus_context.txt"
echo "--- GLASHAUS PROJECT DUMP ---" > "$output"
date >> "$output"

echo -e "\n\n--- GIT HISTORY ---" >> "$output"
git log --oneline --graph --decorate -n 20 >> "$output"

echo -e "\n\n--- FILE STRUCTURE ---" >> "$output"
tree -L 3 -I '.git|__pycache__|*.pyc' >> "$output" 2>/dev/null || find . -maxdepth 3 -not -path '*/.*' >> "$output"

echo -e "\n\n--- FILE CONTENTS ---" >> "$output"
find . -type f \
    -not -path '*/.*' \
    -not -path './glashaus_context.txt' \
    -not -name '*.png' \
    -not -name '*.jpg' \
    -not -name '*.sqlite' \
    | while read -r file; do
    echo -e "\n\n=========================================" >> "$output"
    echo "FILE: $file" >> "$output"
    echo "=========================================" >> "$output"
    cat "$file" >> "$output"
done

echo "Dump complete. Copy contents of $output"


=========================================
FILE: ./prompts/detective_prompt_v1.md
=========================================
# Role: Geospatial & Technical Detective
Analyze the real estate listing. Focus on detecting hidden legal or maintenance risks.

## Constraints
1. **Atelier Check:** Look for "Atelier" in text or industrial/office elements in photos.
2. **Heating:** Identify AC units, radiators, or fireplace.
3. **Era:** Estimate if building is Pre-1989 (Panel/EPC) or Post-2000 (Brick).
4. **Landmarks:** Identify specific street names or shop signs.

## Output Format (JSON Only)
{
  "address_prediction": "String",
  "confidence": 0-100,
  "is_atelier": boolean,
  "reasoning_steps": ["Step 1", "Step 2"],
  "vision_insights": {
    "facade_era": "string",
    "heating_source": "electricity/gas/central",
    "floor_plan_suspicion": "high/low"
  }
}


=========================================
FILE: ./db/schema_v1.sql
=========================================
-- Enable GIS extensions for location logic
CREATE EXTENSION IF NOT EXISTS postgis;

CREATE TABLE buildings (
    id SERIAL PRIMARY KEY,
    cadastre_id VARCHAR(50) UNIQUE NOT NULL, -- The official identifier
    address_street VARCHAR(255),
    address_number VARCHAR(50),
    neighborhood VARCHAR(100),
    gps_coordinates GEOMETRY(Point, 4326),
    construction_year INT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE TABLE listings (
    id SERIAL PRIMARY KEY,
    source_url TEXT UNIQUE NOT NULL,
    price_bgn DECIMAL(12, 2),
    advertised_area_sqm DECIMAL(10, 2),
    description_raw TEXT,
    scraped_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE TABLE reports (
    id SERIAL PRIMARY KEY,
    listing_id INT REFERENCES listings(id),
    building_id INT REFERENCES buildings(id),
    risk_score INT, -- 0 to 100 (100 is Toxic)
    is_address_verified BOOLEAN DEFAULT FALSE,
    discrepancy_details JSONB, -- Stores the "Apartment vs Atelier" logic
    cost_to_generate DECIMAL(10, 4) -- Tracking the $0.22 API cost
);


=========================================
FILE: ./db/migration_001_status_workflow.sql
=========================================
-- 1. Create the Workflow Status Enum
-- This supports the PENDING -> VERIFIED -> MANUAL_REVIEW flow
DO $$ BEGIN
    CREATE TYPE report_status AS ENUM ('PENDING', 'PROCESSING', 'VERIFIED', 'MANUAL_REVIEW', 'REJECTED');
EXCEPTION
    WHEN duplicate_object THEN null;
END $$;

-- 2. Update 'reports' table
ALTER TABLE reports 
ADD COLUMN IF NOT EXISTS status report_status DEFAULT 'PENDING',
ADD COLUMN IF NOT EXISTS ai_confidence_score INT DEFAULT 0,
ADD COLUMN IF NOT EXISTS manual_review_notes TEXT;

-- 3. Update 'listings' table for Idempotency
-- We hash the file/content to prevent duplicate processing of the same upload
ALTER TABLE listings
ADD COLUMN IF NOT EXISTS content_hash VARCHAR(64);

CREATE INDEX IF NOT EXISTS idx_listings_content_hash ON listings(content_hash);

-- 4. Create the Manual Review Queue View
-- This allows the Admin Panel to easily select tasks needing human eyes
CREATE OR REPLACE VIEW view_manual_review_queue AS
SELECT 
    r.id as report_id,
    l.source_url,
    r.ai_confidence_score,
    r.risk_score,
    r.created_at
FROM reports r
JOIN listings l ON r.listing_id = l.id
WHERE r.status = 'MANUAL_REVIEW'
ORDER BY r.risk_score DESC;


=========================================
FILE: ./db/migrations/env.py
=========================================
from logging.config import fileConfig
from sqlalchemy import engine_from_config
from sqlalchemy import pool
from alembic import context
import os
import sys

# Add src to path so we can import models
sys.path.append(os.getcwd())

from src.db.session import Base
from src.core.config import settings
from src.db.models import Listing, Report, Building 

config = context.config

if config.config_file_name is not None:
    fileConfig(config.config_file_name)

# Overwrite config URL with Environment Settings
config.set_main_option("sqlalchemy.url", settings.DATABASE_URL)

target_metadata = Base.metadata

def run_migrations_offline() -> None:
    url = config.get_main_option("sqlalchemy.url")
    context.configure(
        url=url,
        target_metadata=target_metadata,
        literal_binds=True,
        dialect_opts={"paramstyle": "named"},
    )

    with context.begin_transaction():
        context.run_migrations()

def run_migrations_online() -> None:
    connectable = engine_from_config(
        config.get_section(config.config_ini_section, {}),
        prefix="sqlalchemy.",
        poolclass=pool.NullPool,
    )

    with connectable.connect() as connection:
        context.configure(
            connection=connection, target_metadata=target_metadata
        )

        with context.begin_transaction():
            context.run_migrations()

if context.is_offline_mode():
    run_migrations_offline()
else:
    run_migrations_online()


=========================================
FILE: ./db/migrations/versions/migration_003_area_precision.py
=========================================
"""fix_area_precision

Revision ID: 003
Revises: 002
Create Date: 2025-12-19 20:30:00.000000

"""
from alembic import op
import sqlalchemy as sa

# revision identifiers, used by Alembic.
revision = '003'
down_revision = '002'
branch_labels = None
depends_on = None

def upgrade() -> None:
    # 1. Alter Listings Table
    op.alter_column('listings', 'advertised_area_sqm',
               existing_type=sa.Float(),
               type_=sa.Numeric(precision=10, scale=2),
               postgresql_using='advertised_area_sqm::numeric',
               existing_nullable=True)

def downgrade() -> None:
    op.alter_column('listings', 'advertised_area_sqm',
               existing_type=sa.Numeric(precision=10, scale=2),
               type_=sa.Float(),
               existing_nullable=True)


=========================================
FILE: ./db/migration_002_fix_currency.sql
=========================================
-- Fix Financial Precision for Listings and Reports
-- RUN THIS MANUALLY OR VIA ALEMBIC

ALTER TABLE listings 
ALTER COLUMN price_bgn TYPE NUMERIC(12, 2) 
USING price_bgn::numeric;

ALTER TABLE reports
ALTER COLUMN cost_to_generate TYPE NUMERIC(10, 4)
USING cost_to_generate::numeric;

ALTER TABLE price_history
ALTER COLUMN price_bgn TYPE NUMERIC(12, 2)
USING price_bgn::numeric;


=========================================
FILE: ./README.md
=========================================
# GLASHAUS: The Real Estate Integrity Engine

## Mission
To eliminate information asymmetry in the Sofia real estate market via automated due diligence.
We leverage OSINT, LLM reasoning, and Official Registry cross-referencing.

## Architecture
- **Text Layer:** Gemini Flash (Cost optimized)
- **Vision Layer:** Gemini Pro (Geospatial reasoning)
- **Data Layer:** PostgreSQL (Structured) + S3 (Archives)

## Status
- **Phase:** Pre-Alpha / Architectural Blueprint
- **Deploy Target:** Jan 2026 (Launch)


=========================================
FILE: ./requirements.txt
=========================================
fastapi==0.109.0
uvicorn==0.27.0
sqlalchemy==2.0.25
psycopg2-binary==2.9.9
httpx==0.26.0
playwright==1.41.0
asgiref==3.7.2
pydantic==2.6.0
pydantic-settings==2.1.0
google-generativeai>=0.7.0
beautifulsoup4==4.12.3
celery==5.3.6
redis==5.0.1
alembic==1.13.1
Pillow==10.2.0
structlog>=24.1.0


=========================================
FILE: ./imot_simulation.html
=========================================
<!DOCTYPE html>
<html>
<body>
    <div class="list_ads">
        <!-- Mock Listing 1 -->
        <a href="//www.imot.bg/pcgi/imot.cgi?act=5&adv=1c171899111&slink=a4eg0c&f1=1" class="photoLink">
            <div class="text_desc">
                2-STAEN, Sofia, Lozenets, 185 000 EUR
            </div>
        </a>
        
        <!-- Mock Listing 2 -->
        <a href="//www.imot.bg/pcgi/imot.cgi?act=5&adv=2c172200231&slink=a4eg0c&f1=1" class="photoLink">
            <div class="text_desc">
                3-STAEN, Sofia, Krustova Vada, 250 000 EUR, Gas/Elevator
            </div>
        </a>

        <!-- Mock Listing 3 -->
        <a href="//www.imot.bg/pcgi/imot.cgi?act=5&adv=3c17992881&slink=a4eg0c&f1=1" class="photoLink">
            <div class="text_desc">
                ATELIER, Sofia, Center, 90 000 EUR
            </div>
        </a>
    </div>
</body>
</html>


=========================================
FILE: ./Dockerfile
=========================================
# STAGE 1: Builder
FROM python:3.11-slim as builder

WORKDIR /app
RUN apt-get update && apt-get install -y \
    libpq-dev gcc build-essential \
    && rm -rf /var/lib/apt/lists/*

COPY requirements.txt .
RUN pip install --user --no-cache-dir -r requirements.txt

# STAGE 2: Runtime
FROM python:3.11-slim as runtime

WORKDIR /app

# Install only runtime libs (libpq for Postgres)
RUN apt-get update && apt-get install -y \
    libpq5 netcat-openbsd \
    && rm -rf /var/lib/apt/lists/*

# Copy installed packages from builder
COPY --from=builder /root/.local /root/.local
ENV PATH=/root/.local/bin:$PATH

# Copy Application Code
COPY . .

# Create a non-root user for security
RUN useradd -m glashaus_user
USER glashaus_user

EXPOSE 8000

CMD ["uvicorn", "src.main:app", "--host", "0.0.0.0", "--port", "8000"]


=========================================
FILE: ./docker-compose.yml
=========================================
version: '3.8'

services:
  # 1. GATEWAY (Entry Point)
  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
    depends_on:
      - api

  # 2. API (Internal)
  api:
    build: .
    expose:
      - "8000" # Not mapped to host anymore, only accessible via Nginx
    environment:
      - POSTGRES_SERVER=db
      - POSTGRES_USER=glashaus_user
      - POSTGRES_PASSWORD=secret_password
      - POSTGRES_DB=glashaus_db
      - REDIS_URL=redis://redis:6379/0
      # - GEMINI_API_KEY=${GEMINI_API_KEY} # Uncomment for prod
    depends_on:
      - db
      - redis
    volumes:
      - ./src:/app/src

  # 3. WORKER
  worker:
    build: .
    command: celery -A src.worker.celery_app worker --loglevel=info
    environment:
      - POSTGRES_SERVER=db
      - POSTGRES_USER=glashaus_user
      - POSTGRES_PASSWORD=secret_password
      - POSTGRES_DB=glashaus_db
      - REDIS_URL=redis://redis:6379/0
      # - GEMINI_API_KEY=${GEMINI_API_KEY}
    depends_on:
      - db
      - redis
    volumes:
      - ./src:/app/src

  # 4. REDIS
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"

  # 5. DB
  db:
    image: postgis/postgis:15-3.4
    volumes:
      - postgres_data:/var/lib/postgresql/data
    environment:
      - POSTGRES_USER=glashaus_user
      - POSTGRES_PASSWORD=secret_password
      - POSTGRES_DB=glashaus_db
    ports:
      - "5432:5432"

volumes:
  postgres_data:


=========================================
FILE: ./tests/test_api.py
=========================================
from fastapi.testclient import TestClient
from src.main import app

client = TestClient(app)

def test_health_check():
    response = client.get("/")
    assert response.status_code == 200
    assert response.json()["status"] == "OPERATIONAL"

def test_audit_flow():
    payload = {"url": "https://www.imot.bg/pcgi/imot.cgi?act=5&adv=mock123"}
    response = client.post("/audit", json=payload)
    
    assert response.status_code == 200
    data = response.json()
    assert data["status"] == "QUEUED"
    assert "listing_id" in data


=========================================
FILE: ./alembic.ini
=========================================
[alembic]
script_location = db/migrations
prepend_sys_path = .
sqlalchemy.url = driver://user:pass@localhost/dbname

[post_write_hooks]

[loggers]
keys = root,sqlalchemy,alembic

[handlers]
keys = console

[formatters]
keys = generic

[logger_root]
level = WARN
handlers = console
qualname =

[logger_sqlalchemy]
level = WARN
handlers =
qualname = sqlalchemy.engine

[logger_alembic]
level = INFO
handlers =
qualname = alembic

[handler_console]
class = StreamHandler
args = (sys.stderr,)
level = NOTSET
formatter = generic

[formatter_generic]
format = %(levelname)-5.5s [%(name)s] %(message)s
datefmt = %H:%M:%S


=========================================
FILE: ./nginx/nginx.conf
=========================================
events {}

http {
    upstream glashaus_api {
        server api:8000;
    }

    server {
        listen 80;
        
        # Proxy all API requests to the FastAPI container
        location / {
            proxy_pass http://glashaus_api;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        }

        # Health check endpoint
        location /health {
            return 200 'alive';
            add_header Content-Type text/plain;
        }
    }
}


=========================================
FILE: ./cookies.txt
=========================================
# Netscape HTTP Cookie File
# https://curl.se/docs/http-cookies.html
# This file was generated by libcurl! Edit at your own risk.

.imot.bg	TRUE	/	FALSE	0	imot_session_redirect	f1%091%09act%093%09
.imot.bg	TRUE	/	FALSE	1766139545	slink_url	
.imot.bg	TRUE	/	FALSE	1766139545	slink	


=========================================
FILE: ./forensics/headers.txt
=========================================
HTTP/2 200 
date: Fri, 19 Dec 2025 10:22:43 GMT
content-type: text/html
server: cloudflare
vary: Accept-Encoding
set-cookie: imot_session_redirect=adv%091c171899111%09act%095%09; domain=.imot.bg; path=/
referrer-policy: no-referrer-when-downgrade
strict-transport-security: max-age=15552000
nel: {"report_to":"cf-nel","success_fraction":0.0,"max_age":604800}
cf-cache-status: DYNAMIC
report-to: {"group":"cf-nel","max_age":604800,"endpoints":[{"url":"https://a.nel.cloudflare.com/report/v4?s=j9v062ydriN%2F%2BXubjtcJm8HyyWIt5Iad0Ozkt1xE1LO0Maoge0%2FxNlheTZuu%2FtFcpdrE5nQ8tbcs1nOXtqzEhMuYqUOOk1Zv"}]}
cf-ray: 9b062e33d9d0d0d4-SOF
alt-svc: h3=":443"; ma=86400



=========================================
FILE: ./forensics/page_utf8.html
=========================================


=========================================
FILE: ./forensics_dump.html
=========================================
<!DOCTYPE html>
    <html lang="bg">
      <head>
        <title>Ð˜Ð¼Ð¾Ñ‚Ð¸ - Imot.bg - ÐŸÐ°Ð·Ð°Ñ€ÑŠÑ‚ Ð½Ð° Ð½ÐµÐ´Ð²Ð¸Ð¶Ð¸Ð¼Ð¸ Ð¸Ð¼Ð¾Ñ‚Ð¸ - Ð¿Ñ€Ð¾Ð´Ð°Ð¶Ð±Ð¸, Ð½Ð°ÐµÐ¼Ð¸, Ð°Ð³ÐµÐ½Ñ†Ð¸Ð¸, Ð½Ð¾Ð²Ð¸Ð½Ð¸ Ð·Ð° Ð¸Ð¼Ð¾Ñ‚Ð¸ (imoti)</title>
        <meta http-equiv="Content-Type" content="text/html; charset=windows-1251">
        <meta name="description" content="imot.bg - ÐŸÐ°Ð·Ð°Ñ€ÑŠÑ‚ Ð½Ð° Ð½ÐµÐ´Ð²Ð¸Ð¶Ð¸Ð¼Ð¸ Ð¸Ð¼Ð¾Ñ‚Ð¸ Ð² Ð‘ÑŠÐ»Ð³Ð°Ñ€Ð¸Ñ. ÐžÑ„ÐµÑ€Ñ‚Ð¸ Ð·Ð° Ð¿Ñ€Ð¾Ð´Ð°Ð¶Ð±Ð°, Ð¿Ð¾Ð´ Ð½Ð°ÐµÐ¼, ÐºÑƒÐ¿ÑƒÐ²Ð°, Ð½Ð°ÐµÐ¼Ð°, Ð·Ð°Ð¼ÐµÐ½Ñ. ÐÐ³ÐµÐ½Ñ†Ð¸Ð¸ Ð·Ð° Ð¸Ð¼Ð¾Ñ‚Ð¸. ÐÐ¾Ð²Ð¸Ð½Ð¸. Ð¡ÑŠÐ²ÐµÑ‚Ð¸. Ð¡Ñ‚Ñ€Ð¾Ð¸Ñ‚ÐµÐ»ÑÑ‚Ð²Ð¾. ÐžÐ±Ð·Ð°Ð²ÐµÐ¶Ð´Ð°Ð½Ðµ. Ð˜Ð½Ñ‚ÐµÑ€Ð¸Ð¾Ñ€. ÐšÑ€ÐµÐ´Ð¸Ñ‚Ð¸Ñ€Ð°Ð½Ðµ Ð¸ Ð´Ñ€.">
        <link rel="SHORTCUT ICON" href="https://www.imot.bg/favicon.ico"/>
        <link rel="stylesheet" href="/styless/styles.css?633" type="text/css">
        
                <script type="text/javascript" charset="UTF-8" src="//cdn.cookie-script.com/s/5874e0489319507715f52b3fd38d9a7a.js"></script>
        <script type="text/javascript" src="/jss/scripts.js?633"></script>
        <script type="text/javascript" src="/jss/dim.js?633"></script>
        <script type="text/javascript" src="/jss/mobile-detect.min.js?633"></script>
        <script type="text/javascript" src="/jss/jquery.min.js"></script>
        <script type="text/javascript">
        
        
        </script>
        
<script type="text/javascript" src="/jss/ac_runactivecontent.js"></script>
<script type="text/javascript" src="/jss/scriptsJquery.js"></script>
        <script>(function(){/*

 Copyright The Closure Library Authors.
 SPDX-License-Identifier: Apache-2.0
*/
'use strict';var g=function(a){var b=0;return function(){return b<a.length?{done:!1,value:a[b++]}:{done:!0}}},l=this||self,m=/^[\w+/_-]+[=]{0,2}$/,p=null,q=function(){},r=function(a){var b=typeof a;if("object"==b)if(a){if(a instanceof Array)return"array";if(a instanceof Object)return b;var c=Object.prototype.toString.call(a);if("[object Window]"==c)return"object";if("[object Array]"==c||"number"==typeof a.length&&"undefined"!=typeof a.splice&&"undefined"!=typeof a.propertyIsEnumerable&&!a.propertyIsEnumerable("splice"))return"array";
if("[object Function]"==c||"undefined"!=typeof a.call&&"undefined"!=typeof a.propertyIsEnumerable&&!a.propertyIsEnumerable("call"))return"function"}else return"null";else if("function"==b&&"undefined"==typeof a.call)return"object";return b},u=function(a,b){function c(){}c.prototype=b.prototype;a.prototype=new c;a.prototype.constructor=a};var v=function(a,b){Object.defineProperty(l,a,{configurable:!1,get:function(){return b},set:q})};var y=function(a,b){this.b=a===w&&b||"";this.a=x},x={},w={};var aa=function(a,b){a.src=b instanceof y&&b.constructor===y&&b.a===x?b.b:"type_error:TrustedResourceUrl";if(null===p)b:{b=l.document;if((b=b.querySelector&&b.querySelector("script[nonce]"))&&(b=b.nonce||b.getAttribute("nonce"))&&m.test(b)){p=b;break b}p=""}b=p;b&&a.setAttribute("nonce",b)};var z=function(){return Math.floor(2147483648*Math.random()).toString(36)+Math.abs(Math.floor(2147483648*Math.random())^+new Date).toString(36)};var A=function(a,b){b=String(b);"application/xhtml+xml"===a.contentType&&(b=b.toLowerCase());return a.createElement(b)},B=function(a){this.a=a||l.document||document};B.prototype.appendChild=function(a,b){a.appendChild(b)};var C=function(a,b,c,d,e,f){try{var k=a.a,h=A(a.a,"SCRIPT");h.async=!0;aa(h,b);k.head.appendChild(h);h.addEventListener("load",function(){e();d&&k.head.removeChild(h)});h.addEventListener("error",function(){0<c?C(a,b,c-1,d,e,f):(d&&k.head.removeChild(h),f())})}catch(n){f()}};var ba=l.atob("aHR0cHM6Ly93d3cuZ3N0YXRpYy5jb20vaW1hZ2VzL2ljb25zL21hdGVyaWFsL3N5c3RlbS8xeC93YXJuaW5nX2FtYmVyXzI0ZHAucG5n"),ca=l.atob("WW91IGFyZSBzZWVpbmcgdGhpcyBtZXNzYWdlIGJlY2F1c2UgYWQgb3Igc2NyaXB0IGJsb2NraW5nIHNvZnR3YXJlIGlzIGludGVyZmVyaW5nIHdpdGggdGhpcyBwYWdlLg=="),da=l.atob("RGlzYWJsZSBhbnkgYWQgb3Igc2NyaXB0IGJsb2NraW5nIHNvZnR3YXJlLCB0aGVuIHJlbG9hZCB0aGlzIHBhZ2Uu"),ea=function(a,b,c){this.b=a;this.f=new B(this.b);this.a=null;this.c=[];this.g=!1;this.i=b;this.h=c},F=function(a){if(a.b.body&&!a.g){var b=
function(){D(a);l.setTimeout(function(){return E(a,3)},50)};C(a.f,a.i,2,!0,function(){l[a.h]||b()},b);a.g=!0}},D=function(a){for(var b=G(1,5),c=0;c<b;c++){var d=H(a);a.b.body.appendChild(d);a.c.push(d)}b=H(a);b.style.bottom="0";b.style.left="0";b.style.position="fixed";b.style.width=G(100,110).toString()+"%";b.style.zIndex=G(2147483544,2147483644).toString();b.style["background-color"]=I(249,259,242,252,219,229);b.style["box-shadow"]="0 0 12px #888";b.style.color=I(0,10,0,10,0,10);b.style.display=
"flex";b.style["justify-content"]="center";b.style["font-family"]="Roboto, Arial";c=H(a);c.style.width=G(80,85).toString()+"%";c.style.maxWidth=G(750,775).toString()+"px";c.style.margin="24px";c.style.display="flex";c.style["align-items"]="flex-start";c.style["justify-content"]="center";d=A(a.f.a,"IMG");d.className=z();d.src=ba;d.style.height="24px";d.style.width="24px";d.style["padding-right"]="16px";var e=H(a),f=H(a);f.style["font-weight"]="bold";f.textContent=ca;var k=H(a);k.textContent=da;J(a,
e,f);J(a,e,k);J(a,c,d);J(a,c,e);J(a,b,c);a.a=b;a.b.body.appendChild(a.a);b=G(1,5);for(c=0;c<b;c++)d=H(a),a.b.body.appendChild(d),a.c.push(d)},J=function(a,b,c){for(var d=G(1,5),e=0;e<d;e++){var f=H(a);b.appendChild(f)}b.appendChild(c);c=G(1,5);for(d=0;d<c;d++)e=H(a),b.appendChild(e)},G=function(a,b){return Math.floor(a+Math.random()*(b-a))},I=function(a,b,c,d,e,f){return"rgb("+G(Math.max(a,0),Math.min(b,255)).toString()+","+G(Math.max(c,0),Math.min(d,255)).toString()+","+G(Math.max(e,0),Math.min(f,
255)).toString()+")"},H=function(a){a=A(a.f.a,"DIV");a.className=z();return a},E=function(a,b){0>=b||null!=a.a&&0!=a.a.offsetHeight&&0!=a.a.offsetWidth||(fa(a),D(a),l.setTimeout(function(){return E(a,b-1)},50))},fa=function(a){var b=a.c;var c="undefined"!=typeof Symbol&&Symbol.iterator&&b[Symbol.iterator];b=c?c.call(b):{next:g(b)};for(c=b.next();!c.done;c=b.next())(c=c.value)&&c.parentNode&&c.parentNode.removeChild(c);a.c=[];(b=a.a)&&b.parentNode&&b.parentNode.removeChild(b);a.a=null};var ia=function(a,b,c,d,e){var f=ha(c),k=function(n){n.appendChild(f);l.setTimeout(function(){f?(0!==f.offsetHeight&&0!==f.offsetWidth?b():a(),f.parentNode&&f.parentNode.removeChild(f)):a()},d)},h=function(n){document.body?k(document.body):0<n?l.setTimeout(function(){h(n-1)},e):b()};h(3)},ha=function(a){var b=document.createElement("div");b.className=a;b.style.width="1px";b.style.height="1px";b.style.position="absolute";b.style.left="-10000px";b.style.top="-10000px";b.style.zIndex="-10000";return b};var K={},L=null;var M=function(){},N="function"==typeof Uint8Array,O=function(a,b){a.b=null;b||(b=[]);a.j=void 0;a.f=-1;a.a=b;a:{if(b=a.a.length){--b;var c=a.a[b];if(!(null===c||"object"!=typeof c||Array.isArray(c)||N&&c instanceof Uint8Array)){a.g=b-a.f;a.c=c;break a}}a.g=Number.MAX_VALUE}a.i={}},P=[],Q=function(a,b){if(b<a.g){b+=a.f;var c=a.a[b];return c===P?a.a[b]=[]:c}if(a.c)return c=a.c[b],c===P?a.c[b]=[]:c},R=function(a,b,c){a.b||(a.b={});if(!a.b[c]){var d=Q(a,c);d&&(a.b[c]=new b(d))}return a.b[c]};
M.prototype.h=N?function(){var a=Uint8Array.prototype.toJSON;Uint8Array.prototype.toJSON=function(){var b;void 0===b&&(b=0);if(!L){L={};for(var c="ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789".split(""),d=["+/=","+/","-_=","-_.","-_"],e=0;5>e;e++){var f=c.concat(d[e].split(""));K[e]=f;for(var k=0;k<f.length;k++){var h=f[k];void 0===L[h]&&(L[h]=k)}}}b=K[b];c=[];for(d=0;d<this.length;d+=3){var n=this[d],t=(e=d+1<this.length)?this[d+1]:0;h=(f=d+2<this.length)?this[d+2]:0;k=n>>2;n=(n&
3)<<4|t>>4;t=(t&15)<<2|h>>6;h&=63;f||(h=64,e||(t=64));c.push(b[k],b[n],b[t]||"",b[h]||"")}return c.join("")};try{return JSON.stringify(this.a&&this.a,S)}finally{Uint8Array.prototype.toJSON=a}}:function(){return JSON.stringify(this.a&&this.a,S)};var S=function(a,b){return"number"!==typeof b||!isNaN(b)&&Infinity!==b&&-Infinity!==b?b:String(b)};M.prototype.toString=function(){return this.a.toString()};var T=function(a){O(this,a)};u(T,M);var U=function(a){O(this,a)};u(U,M);var ja=function(a,b){this.c=new B(a);var c=R(b,T,5);c=new y(w,Q(c,4)||"");this.b=new ea(a,c,Q(b,4));this.a=b},ka=function(a,b,c,d){b=new T(b?JSON.parse(b):null);b=new y(w,Q(b,4)||"");C(a.c,b,3,!1,c,function(){ia(function(){F(a.b);d(!1)},function(){d(!0)},Q(a.a,2),Q(a.a,3),Q(a.a,1))})};var la=function(a,b){V(a,"internal_api_load_with_sb",function(c,d,e){ka(b,c,d,e)});V(a,"internal_api_sb",function(){F(b.b)})},V=function(a,b,c){a=l.btoa(a+b);v(a,c)},W=function(a,b,c){for(var d=[],e=2;e<arguments.length;++e)d[e-2]=arguments[e];e=l.btoa(a+b);e=l[e];if("function"==r(e))e.apply(null,d);else throw Error("API not exported.");};var X=function(a){O(this,a)};u(X,M);var Y=function(a){this.h=window;this.a=a;this.b=Q(this.a,1);this.f=R(this.a,T,2);this.g=R(this.a,U,3);this.c=!1};Y.prototype.start=function(){ma();var a=new ja(this.h.document,this.g);la(this.b,a);na(this)};
var ma=function(){var a=function(){if(!l.frames.googlefcPresent)if(document.body){var b=document.createElement("iframe");b.style.display="none";b.style.width="0px";b.style.height="0px";b.style.border="none";b.style.zIndex="-1000";b.style.left="-1000px";b.style.top="-1000px";b.name="googlefcPresent";document.body.appendChild(b)}else l.setTimeout(a,5)};a()},na=function(a){var b=Date.now();W(a.b,"internal_api_load_with_sb",a.f.h(),function(){var c;var d=a.b,e=l[l.btoa(d+"loader_js")];if(e){e=l.atob(e);
e=parseInt(e,10);d=l.btoa(d+"loader_js").split(".");var f=l;d[0]in f||"undefined"==typeof f.execScript||f.execScript("var "+d[0]);for(;d.length&&(c=d.shift());)d.length?f[c]&&f[c]!==Object.prototype[c]?f=f[c]:f=f[c]={}:f[c]=null;c=Math.abs(b-e);c=1728E5>c?0:c}else c=-1;0!=c&&(W(a.b,"internal_api_sb"),Z(a,Q(a.a,6)))},function(c){Z(a,c?Q(a.a,4):Q(a.a,5))})},Z=function(a,b){a.c||(a.c=!0,a=new l.XMLHttpRequest,a.open("GET",b,!0),a.send())};(function(a,b){l[a]=function(c){for(var d=[],e=0;e<arguments.length;++e)d[e-0]=arguments[e];l[a]=q;b.apply(null,d)}})("__d3lUW8vwsKlB__",function(a){"function"==typeof window.atob&&(a=window.atob(a),a=new X(a?JSON.parse(a):null),(new Y(a)).start())});}).call(this);

window.__d3lUW8vwsKlB__("WyI0YTBhODk3MmZlNzIwMDgwIixbbnVsbCxudWxsLG51bGwsImh0dHBzOi8vZnVuZGluZ2Nob2ljZXNtZXNzYWdlcy5nb29nbGUuY29tL2YvQUdTS1d4VWhqXzdlWWM2MzVYbk5ZTkgteWdXaEZTOXRDdmh5S21va1pQQkNyTkRBX2YwdUNYSTFweHJSQk9fdjBkVlB1cUJPb3kxaDg1YXlzd01rOVZKSVRmd1x1MDAzZCJdCixbMjAsImRpdi1ncHQtYWQiLDEwMCwiTkdFd1lUZzVOekptWlRjeU1EQTRNQVx1MDAzZFx1MDAzZCIsW251bGwsbnVsbCxudWxsLCJodHRwczovL3d3dy5nc3RhdGljLmNvbS8wZW1uL2YvcC80YTBhODk3MmZlNzIwMDgwLmpzP3VzcXBcdTAwM2RDQTAiXQpdCiwiaHR0cHM6Ly9mdW5kaW5nY2hvaWNlc21lc3NhZ2VzLmdvb2dsZS5jb20vbC9BR1NLV3hXTmFTeEhpaVBkOURldjdGWl9ZbUNpSklOQmVmQjQ4WkJ5VVc2eG5XTnJGcWQ3OXRGVmlsZEt3Ti12ZTlLX254eUVBT19FUF9wQWNsdEFfTlF0P2FiXHUwMDNkMSIsImh0dHBzOi8vZnVuZGluZ2Nob2ljZXNtZXNzYWdlcy5nb29nbGUuY29tL2wvQUdTS1d4WEdqdFhkREs5NW13RXAwajhnOGZ4eDlLZmtpNDlsSTJrdmxXTzJxaFZhZ2hIXy1YNWtnUml6aF9FZW1xZW9HN0RJNmE3SDZoLVVCMUd3ZTdBZT9hYlx1MDAzZDJcdTAwMjZzYmZcdTAwM2QxIiwiaHR0cHM6Ly9mdW5kaW5nY2hvaWNlc21lc3NhZ2VzLmdvb2dsZS5jb20vbC9BR1NLV3hXRmktTGk1cjBoeGljcDJkOGN1aUlWMGQ2MTUxZ0ZtbGVWLS1nTjdaSnB3ZTgyMVFsY0RkNjlleW8xck1PMjVQQl8zU2x2c2plWWhyMVRxVEZ1P3NiZlx1MDAzZDIiXQo=");</script>
        <script defer async src="https://www.googletagmanager.com/gtag/js?id=G-0LZF32451N"></script>
        <script>
        const gtagLoaded = new Event('gtag-loaded');(function(d, s, id){var js, fjs = d.getElementsByTagName(s)[0];if (d.getElementById(id)) {return;}js = d.createElement(s);js.id = id;js.defer = true;js.async = true;js.src = "https://www.googletagmanager.com/gtag/js?id=G-0LZF32451N";js.onload = function(){document.dispatchEvent(gtagLoaded);};fjs.parentNode.insertBefore(js, fjs);}(document, 'script', 'gtag-js'));try {window.dataLayer = window.dataLayer || [];function gtag(){dataLayer.push(arguments);}gtag('js', new Date());gtag('config', 'G-0LZF32451N');gtag('config', 'UA-1160575-1');}catch(error){}
        </script>

        <script async="async" src="https://www.googletagservices.com/tag/js/gpt.js"></script>
        <script>
          var googletag = googletag || {};
          googletag.cmd = googletag.cmd || [];
        </script>
        <script>
          googletag.cmd.push(function() {
            googletag.pubads().set("adsense_background_color", "FFFFFF");
          });
        </script>
        <script>
        googletag.cmd.push(function() {
          

          googletag.pubads().enableSingleRequest();
          googletag.enableServices();
        });
        </script>

      </head>
      <body onload="javascript: if(window.startw)startw();">

      
      <div class="imotPhotosIframe" id="imotPhotos"></div>

      <div style="text-align:left; z-index:1; position:relative; margin: 0 auto 10px auto; width:980px; cursor:auto;">
      


  <div class="regWindow" id="langWindow">
    <div class="panel" style="width:700px; left: 0">
      <div class="formVhod shareWindow" style="border-radius:10px;width:700px;">
        <a href="javascript:closLangWindow();" class="close" title="Ð—Ð°Ñ‚Ð²Ð¾Ñ€Ð¸" style="margin-left:645px;"></a>
        <div class="price-stat">
          <div class="shareOptions" style="width:660px">
            <div class="boxTITLE">Translations in other languages:</div>
            <div class="TITLE">
              All real estate ads published on <span style="color: #900;">imot.bg</span> have been translated into English and published on the partner site
              <br>
              <img src="//www.imot.bg/images/picturess/icons/imoti-info-logo.svg" style="margin-top: 12px; height: 38px;">
            </div>

            <div class="screen1">
              <div class="emailGrid" style="grid-gap:0">
                <div class="C4">
                  <a href="https://imoti.info/en" class="send gotoSite" target="_blank" onclick="closLangWindow();">Continue</a>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>

<script type="module">
                        import { initializeApp } from "https://www.gstatic.com/firebasejs/9.6.6/firebase-app.js";
                        import { onMessage, isSupported, getMessaging } from "https://www.gstatic.com/firebasejs/9.6.6/firebase-messaging.js";

                        isSupported().then((isSuppored) => {
                          if (isSuppored) {
                            var fcm=getcookieval('fcm');
                            try {
                              fcm = JSON.parse(decodeURIComponent(fcm));
                            } catch (err) {
                              fcm = {};
                            }

                            if (fcm.status == 'agree')
                              receiveFCM();

                            function receiveFCM() {

                              initializeApp({ apiKey: "AIzaSyDl3rtJjr6tZw0gJrtZlECkn8L0rWWVaRA",
                                authDomain: "imot-466de.firebaseapp.com",
                                databaseURL: "https://imot-466de.firebaseio.com",
                                projectId: "imot-466de",
                                storageBucket: "imot-466de.appspot.com",
                                messagingSenderId: "647267607875",
                                appId: "1:647267607875:web:1bef151e4da339c07b3bf6"
                              });

                              const messaging = getMessaging();
                              onMessage(messaging, (payload) => {

                                if (payload && payload.data && payload.data.type === 'newadv')
                                  {
                                    document.getElementById('notification-popup').style.display='block';
                                    document.getElementById('notification-popup').style.opacity='1';
                                    document.getElementById('notification-popup-bodyonly').innerHTML = payload.data.bodyonly;
                                    document.getElementById('notification-popup-bodyonly').href = payload.data.url;
                                    document.getElementById('notification-popup-span-price').innerHTML = payload.data.price;
                                    document.getElementById('notification-popup-area').innerHTML = payload.data.area;
                                    document.getElementById('notification-popup-town').innerHTML = payload.data.town;
                                    document.getElementById('notification-popup-href-img').href = payload.data.url;

                                    if (payload.data.image)
                                      {
                                        document.getElementById('notification-popup-img').src = payload.notification.image;
                                        document.getElementById('notification-popup-img').alt = payload.data.bodyonly;
                                      }
                                  }
                                else if (payload && payload.data && payload.data.type === 'newprice')
                                  {
                                    document.getElementById('notification-popup-price').style.display='block';
                                    document.getElementById('notification-popup-price').style.opacity='1';

                                    document.getElementById('notification-popup-price-bodyonly').innerHTML = payload.data.advinfo;
                                    document.getElementById('notification-popup-price-bodyonly').href = payload.data.url;
                                    document.getElementById('notification-popup-price-old').innerHTML = payload.data.old_price;
                                    document.getElementById('notification-popup-price-new').innerHTML = payload.data.new_price;
                                    document.getElementById('notification-popup-price-href-img').href = payload.data.url;

                                    if (payload.notification.image)
                                      {
                                        document.getElementById('notification-popup-price-img').src = payload.notification.image;
                                        document.getElementById('notification-popup-price-img').alt = payload.data.advinfo;
                                      }
                                  }
                              });
                           }

                           function closeNotification() {
                             document.getElementById('notification-popup').style.display='none';
                             document.getElementById('notification-popup-price').style.display='none';
                           }

                           window.closeNotification = closeNotification;
                          }
                        })
                     </script>
                     <div class="logPopup" id="notification-popup">
                       <div class="newLogin" style="width:520px;padding-top:0;">
                         <a href="javascript:closeNotification();" class="close" style="position: relative; left:435px; top:40px;"></a>
                         <div class="formsWrapper">
                           <div style="font-size:14px; display:block; border-bottom:1px solid #b01110; font-weight:bold; margin-bottom:15px; padding-bottom:5px; width:94%; height: 25px;">
                             ÐŸÐ¾Ð»ÑƒÑ‡Ð¸Ñ…Ñ‚Ðµ Ð½Ð¾Ð²Ð° Ð¾Ð±ÑÐ²Ð° Ð¿Ð¾ Ñ„Ð¸Ð»Ñ‚ÑŠÑ€
                           </div>

                           <a href="" class="photoLink" style="float: left;" id="notification-popup-href-img" onclick="closeNotification();">
                             <img src="../images/picturess/nophoto_490x341.svg" style="object-fit: cover; max-width: 120px; max-height: 100px;" class="noborder" id="notification-popup-img" alt="">
                           </a>

                           <div style="font-size:14px; float: right; width:290px; white-space: nowrap; word-break: break-all; text-overflow: ellipsis; overflow: hidden;">
                             <a href="" style="text-decoration: underline;font-size: 14px;font-weight: bold;color: #000;" id="notification-popup-bodyonly" onclick="closeNotification();"></a><br/><br>
                             <strong style="color: #b01110;" id="notification-popup-span-price"></strong><br/>
                             <span id="notification-popup-area"></span><br/>
                             <span id="notification-popup-town"></span><br/>
                           </div>
                           <div style="clear: both;"></div>
                         </div>
                       </div>
                     </div>

                     <div class="logPopup" id="notification-popup-price" style="">
                       <div class="newLogin" style="width:520px;padding-top:0;">
                         <a href="javascript:closeNotification();" class="close" style="position: relative; left:435px; top:40px;"></a>
                         <div class="formsWrapper">
                           <div style="font-size:14px; display:block; border-bottom:1px solid #b01110; font-weight:bold; margin-bottom:15px; padding-bottom:5px; width:94%; height: 25px;">
                             ÐŸÑ€Ð¾Ð¼ÑÐ½Ð° Ð½Ð° Ñ†ÐµÐ½Ð° Ð½Ð° Ð½Ð°Ð±Ð»ÑŽÐ´Ð°Ð²Ð°Ð½Ð° Ð¾Ð±ÑÐ²Ð°
                           </div>

                           <a href="" class="photoLink" style="float: left;" id="notification-popup-price-href-img" onclick="closeNotification();">
                             <img src="../images/picturess/nophoto_490x341.svg" style="object-fit: cover; max-width: 120px; max-height: 100px;" class="noborder" id="notification-popup-price-img" alt="">
                           </a>

                           <div style="font-size:14px; float: right; width:290px">
                             <a href="" style="text-decoration: underline;font-size: 14px;font-weight: bold;color: #000;" id="notification-popup-price-bodyonly"></a><br/><br>

                             ÑÑ‚Ð°Ñ€Ð° Ñ†ÐµÐ½Ð° <span style="color: #b01110;" id="notification-popup-price-old"></span> <br/>
                             Ð½Ð¾Ð²Ð° Ñ†ÐµÐ½Ð° <strong style="color: #b01110;" id="notification-popup-price-new"></strong>
                           </div>
                           <div style="clear: both;"></div>
                         </div>
                       </div>
                     </div>


  <div class="header">
    <a href="//www.imot.bg" class="left" style="text-decoration:none;">
      <img src="//www.imot.bg/images/picturess/logo.svg" style="width:212px; height:65px;" alt="imot.bg â€“ Ð¾Ð±ÑÐ²Ð¸ Ð·Ð° Ð¿Ñ€Ð¾Ð´Ð°Ð¶Ð±Ð¸ Ð¸ Ð½Ð°ÐµÐ¼Ð¸ Ð½Ð° Ð¸Ð¼Ð¾Ñ‚Ð¸">
      <div class="iSlogan">Ð¡Ð°Ð¹Ñ‚ Ð·Ð° Ð¸Ð¼Ð¾Ñ‚Ð¸ <strong>â„–1</strong></div>
    </a>
    <div id="logtable2" class="right">
      
  
  <div class="regWindow" id="langWindow">
    <div class="panel" style="width:700px; left: 0">
      <div class="formVhod shareWindow" style="border-radius:10px;width:700px;">
        <a href="javascript:closLangWindow();" class="close" title="Ð—Ð°Ñ‚Ð²Ð¾Ñ€Ð¸" style="margin-left:645px;"></a>
        <div class="price-stat">
          <div class="shareOptions" style="width:660px">
            <div class="boxTITLE">Translations in other languages:</div>
            <div class="TITLE">
              All real estate ads published on <span style="color: #900;">imot.bg</span> have been translated into English and published on the partner site
              <br>
              <img src="//www.imot.bg/images/picturess/icons/imoti-info-logo.svg" style="margin-top: 12px; height: 38px;">
            </div>

            <div class="screen1">
              <div class="emailGrid" style="grid-gap:0">
                <div class="C4">
                  <a href="https://imoti.info/en" class="send gotoSite" target="_blank" onclick="closLangWindow();">Continue</a>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
  <div class="logPopup" id="logpopup"></div>
  <a class="flagBtn" onclick="ShowLangWindow();"><img src="//www.imot.bg/images/picturess/icons/flag-en.svg"></a>
  <a data-link="//www.imot.bg/pcgi/imot.cgi?act=1" class="clever-link addButton"><img src="//www.imot.bg/images/picturess/plus.svg"> Ð”ÐžÐ‘ÐÐ’Ð˜ ÐžÐ‘Ð¯Ð’Ð</a>
  
      <a data-link="//www.imot.bg/pcgi/imot.cgi?act=26&rub=0" class="clever-link editButton">Ð ÐµÐ´Ð°ÐºÑ†Ð¸Ñ Ð½Ð° Ð¾Ð±ÑÐ²Ð°</a>
      <div class="loginLinks">
        <span class="logIn">
          <a href="//www.imot.bg/pcgi/imot.cgi?act=26&logact=1"><strong>Ð’Ñ…Ð¾Ð´</strong></a> | <a href="//www.imot.bg/pcgi/imot.cgi?act=26&logact=2">ÐÐ¾Ð²Ð° Ð ÐµÐ³Ð¸ÑÑ‚Ñ€Ð°Ñ†Ð¸Ñ</a>
        </span>
      </div>
      
  
  
    </div>
  </div>
  <div class="iMenu">
    <a href="//www.imot.bg" class="">ÐÐ°Ñ‡Ð°Ð»Ð¾</a>
    <a href="//www.imot.bg/pcgi/imot.cgi?act=1" class="">ÐŸÑƒÐ±Ð»Ð¸ÐºÑƒÐ²Ð°Ð½Ðµ</a>
    <a href="//www.imot.bg/search" class="selected">Ð¢ÑŠÑ€ÑÐµÐ½Ðµ</a>
    <a href="//www.imot.bg/pcgi/imot.cgi?act=7" class="">ÐÐ¾Ð²Ð¸ ÑÐ³Ñ€Ð°Ð´Ð¸</a>
    <a href="//www.imot.bg/agentsii" class="">ÐÐ³ÐµÐ½Ñ†Ð¸Ð¸</a>
    <a href="https://fakti.bg" target="_blank">ÐÐ¾Ð²Ð¸Ð½Ð¸</a>
    <a href="https://creditcenter.bg/buy-new-home" target="_blank">ÐšÑ€ÐµÐ´Ð¸Ñ‚Ð¸</a>
    <div class="imimmore">
      <a href="//www.imot.bg/more-services" class="oshte ">+ ÐžÑ‰Ðµ...</a>
      <div class="down-menu">
        <a href="//www.imot.bg/sredni-ceni" class="sredni">Ð¡Ñ€ÐµÐ´Ð½Ð¸ Ñ†ÐµÐ½Ð¸ Ð½Ð° Ð¸Ð¼Ð¾Ñ‚Ð¸Ñ‚Ðµ</a>
        <a href="//www.imot.bg/ocenka-na-imot" class="kolko">ÐšÐ¾Ð»ÐºÐ¾ ÑÑ‚Ñ€ÑƒÐ²Ð° Ð¼Ð¾ÑÑ‚ Ð¸Ð¼Ð¾Ñ‚?</a>
        <a data-link="//www.imot.bg/searcharch" class="clever-link arhivni" style="cursor:pointer;">ÐÑ€Ñ…Ð¸Ð²Ð½Ð¸ Ð´Ð°Ð½Ð½Ð¸</a>
        <a href="//www.imot.bg/imoti-s-padashti-ceni" class="padashti">Ð˜Ð¼Ð¾Ñ‚Ð¸ Ñ Ð¿Ð°Ð´Ð°Ñ‰Ð¸ Ñ†ÐµÐ½Ð¸</a>
      </div>
    </div>
    <span id="logtable3"><a href="//www.imot.bg/pcgi/imot.cgi?act=26" class="right">ÐœÐ¾ÑÑ‚ Ð¸Ð¼Ð¾Ñ‚</a></span>
    <div class="bottomLine"></div>
  </div>
  




  <div class="pageMessageAlert page980 MT20">
    Ð¢ÑŠÑ€ÑÐµÐ½Ð°Ñ‚Ð° Ð¾Ñ‚ Ð’Ð°Ñ Ð¾Ð±ÑÐ²Ð° Ðµ Ð¸Ð·Ñ‚Ñ€Ð¸Ñ‚Ð° Ð¸Ð»Ð¸ Ð½Ðµ Ðµ Ð°ÐºÑ‚Ð¸Ð²Ð½Ð°.
  </div>
  <div class="width980px margincent">
    <div class="center m-t-20 m-b-20" style="font-size: 18px;">ÐœÐ¾Ð»Ñ Ñ€Ð°Ð·Ð³Ð»eÐ´Ð°Ð¹Ñ‚Ðµ Ð½Ð°Ð¹-Ð½Ð¾Ð²Ð¸Ñ‚Ðµ Ð¿Ð¾Ð´Ð¾Ð±Ð½Ð¸ Ð¾Ð±ÑÐ²Ð¸, Ð¿ÑƒÐ±Ð»Ð¸ÐºÑƒÐ²Ð°Ð½Ð¸ Ð¿Ñ€ÐµÐ· Ð¿Ð¾ÑÐ»ÐµÐ´Ð½Ð¸Ñ‚Ðµ 24 Ñ‡Ð°ÑÐ° Ð² imot.bg</div>
  </div>
  <div class="ads2023">
    
  </div>




  <div class="seoBox" id="seoBox" style="margin:0">
                   
                 </div>
  <div style="width:100%; margin-top:10px; text-align: right;">
    <a href="//www.imot.bg/contacts" class="footLinks1" style="font-weight:normal; color:#900; text-decoration:underline;">Ð’ÑŠÐ¿Ñ€Ð¾ÑÐ¸ Ð¸ Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ ÐºÑŠÐ¼ imot.bg</a>
  </div>
  <div style="width:100%; margin-top:10px;">
    <a href="//www.imot.bg/contacts" class="footLinks1">ÐšÐžÐÐ¢ÐÐšÐ¢Ð˜</a> |
    <a href="//www.imot.bg/pcgi/imot.cgi?act=12" class="footLinks1">SMS ÐšÐžÐ”ÐžÐ’Ð•</a> |
    <a href="//www.imot.bg/help" class="footLinks1">ÐŸÐžÐœÐžÐ©</a> |
    <a href="//www.imot.bg/obshti-uslovia" class="footLinks1">ÐžÐ‘Ð©Ð˜ Ð£Ð¡Ð›ÐžÐ’Ð˜Ð¯</a> |
    <a href="https://rezonmedia.bg/tarifi/imot" class="footLinks1" target="_blank">Ð Ð•ÐšÐ›ÐÐœÐ</a> |
    <a href="//www.imot.bg/zashtita-na-lichni-danni" class="footLinks1">Ð—ÐÐ©Ð˜Ð¢Ð ÐÐ Ð›Ð˜Ð§ÐÐ˜Ð¢Ð• Ð”ÐÐÐÐ˜</a> |
    <a href="//www.imot.bg/sitemap" class="footLinks1">ÐšÐÐ Ð¢Ð ÐÐ Ð¡ÐÐ™Ð¢Ð</a> |
  </div>
  <div style="margin-top:10px; background-color: #900; color:#FFF; padding-left:10px; height:26px; line-height:26px;">
    <a href="https://rezonmedia.bg" target="_blank" class="footLinks2">Ð ÐµÐ·Ð¾Ð½ ÐœÐµÐ´Ð¸Ñ</a> |
    <a href="//www.imot.bg" target="_blank" class="footLinks2">Ð˜Ð¼Ð¾Ñ‚Ð¸</a> |
    <a href="http://www.mobile.bg" target="_blank" class="footLinks2">ÐÐ²Ñ‚Ð¾Ð¼Ð¾Ð±Ð¸Ð»Ð¸</a> |
    <a href="https://www.zaplata.bg" target="_blank" class="footLinks2" title="ÐžÐ±ÑÐ²Ð¸ Ð·Ð° Ñ€Ð°Ð±Ð¾Ñ‚Ð° Ð² Ð‘ÑŠÐ»Ð³Ð°Ñ€Ð¸Ñ Ð¸ Ñ‡ÑƒÐ¶Ð±Ð¸Ð½Ð°">Ð Ð°Ð±Ð¾Ñ‚Ð°</a> |
    <a href="https://www.fakti.bg" target="_blank" class="footLinks2" title="Ð¡ÑŠÐ±Ð¸Ñ‚Ð¸Ñ Ð¾Ñ‚ Ð‘ÑŠÐ»Ð³Ð°Ñ€Ð¸Ñ Ð¸ ÑÐ²ÐµÑ‚Ð°">ÐÐ¾Ð²Ð¸Ð½Ð¸</a> |
    <a href="https://bazar.bg" target="_blank" class="footLinks2">ÐžÐ±ÑÐ²Ð¸</a> |
    <a href="https://prevodirezon.bg" target="_blank" class="footLinks2">ÐŸÑ€ÐµÐ²Ð¾Ð´Ð¸ Ð¸ Ð»ÐµÐ³Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ</a>
    <span style="float: right; margin-right:5px;">2002-2025 &reg;  Copyright imot.bg</span>
  </div>
  <div id="mob_version" style="width:100%; text-align:center;"></div>
  <script>
    var mvc=getCookie('full');
    var mvd=document.getElementById("mob_version");
    if ( mvd && (mvc==1) )
      mvd.innerHTML='<br><a href="https://m.imot.bg" class="footLinks1" onclick="document.cookie=\'full=0; expires=Thu, 01 Jan 1970 00:00:01 GMT; path=/; domain=.imot.bg\'"><u>ÐœÐ¾Ð±Ð¸Ð»Ð½Ð° Ð²ÐµÑ€ÑÐ¸Ñ</u></a>';
  </script>
  <div class="hosting">Â© <strong>imot.bg</strong> Ð¿Ð¾Ð»Ð·Ð²Ð° Ð¸ Ð¿Ñ€ÐµÐ¿Ð¾Ñ€ÑŠÑ‡Ð²Ð° <strong>Ñ…Ð¾ÑÑ‚Ð¸Ð½Ð³ ÑƒÑÐ»ÑƒÐ³Ð¸Ñ‚Ðµ</strong> Ð½Ð° <a href="https://bulinfo.net" target="_blank"><strong><img src="//www.imot.bg/images/picturess/bulinfo-logo.svg" alt="Bulinfo.net"></strong></a></div>
  <div class="follow-us">
    <div>Ð¡Ð»ÐµÐ´Ð²Ð°Ð¹Ñ‚Ðµ Ð½Ð¸ Ð²:</div>
    <a href="https://www.instagram.com/imot.bg/?igsh=MXd6emtpd3kyb2E3dQ%3D%3D" class="follow-us-instagram" target="_blank" title="ÐŸÐ¾ÑÐ»ÐµÐ´Ð²Ð°Ð¹ Ð½Ð¸ Ð² Instagram"></a>
    <a href="https://www.tiktok.com/@imot_bg?_t=ZN-8yTupjIOizC" class="follow-us-tiktok" target="_blank" title="ÐŸÐ¾ÑÐ»ÐµÐ´Ð²Ð°Ð¹ Ð½Ð¸ Ð² TikTok"></a>
    <a href="https://www.facebook.com/imot.bg" class="follow-us-facebook" target="_blank" title="ÐŸÐ¾ÑÐ»ÐµÐ´Ð²Ð°Ð¹ Ð½Ð¸ Ð² Facebook"></a>
    <a href="https://www.youtube.com/@Imot.bg_Official" class="follow-us-youtube" target="_blank" title="ÐŸÐ¾ÑÐ»ÐµÐ´Ð²Ð°Ð¹ Ð½Ð¸ Ð² YouTube"></a>
  </div>
  



      </div>

      <br>
      <div id="logtable" class="LB-white-content" style="width:530px; height:450px;"></div>
      <div id="sendpmessage" class="LB-white-content" style="width:590px; height:465px; left: 20%; position: absolute; top: 50px; display: none;"></div>

      <script type="text/javascript" src="/jss/sticky.js"></script>

      <script>cleverLinks();</script>

      <!-- (C)2000-2014 Gemius SA - gemiusAudience / imot.bg / Home Page -->
      <script type="text/javascript">
      <!--//--><![CDATA[//><!--
      var pp_gemius_identifier = 'p8ZKf3ughze7qeDBCa1hhJQ5XkGiDSOqlz_uKt6qu_X.M7';
      // lines below shouldn't be edited
      function gemius_pending(i) { window[i] = window[i] || function() {var x = window[i+'_pdata'] = window[i+'_pdata'] || []; x[x.length]=arguments;};};
      gemius_pending('gemius_hit'); gemius_pending('gemius_event'); gemius_pending('pp_gemius_hit'); gemius_pending('pp_gemius_event');
      (function(d,t) {try {var gt=d.createElement(t),s=d.getElementsByTagName(t)[0],l='http'+((location.protocol=='https:')?'s':''); gt.setAttribute('async','async');
      gt.setAttribute('defer','defer'); gt.src=l+'://gabg.hit.gemius.pl/xgemius.js'; s.parentNode.insertBefore(gt,s);} catch (e) {}})(document,'script');
      //--><!]]>
      </script>

      <!--  -->
      </body>
    </html>
    

=========================================
FILE: ./bypass_audit.py
=========================================
import httpx
from bs4 import BeautifulSoup
import time
import re

def bypass_audit(url):
    # Professional Browser Headers
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
        "Accept": "text/html,application/xhtml+xml,xml;q=0.9,image/avif,image/webp,*/*;q=0.8",
        "Accept-Language": "bg-BG,bg;q=0.9,en-US;q=0.8,en;q=0.7",
        "Referer": "https://www.google.bg/",
        "Connection": "keep-alive",
        "Upgrade-Insecure-Requests": "1",
        "Sec-Fetch-Dest": "document",
        "Sec-Fetch-Mode": "navigate",
        "Sec-Fetch-Site": "cross-site",
    }

    # Use a Client to maintain Cookies
    with httpx.Client(headers=headers, follow_redirects=True, timeout=20.0) as client:
        print("[*] STEP 1: Handshake with Home Page...")
        home_resp = client.get("https://www.imot.bg")
        print(f"[+] Home Page Status: {home_resp.status_code}")
        print(f"[+] Cookies Acquired: {list(client.cookies.keys())}")

        print("[*] STEP 2: Waiting (Simulating Human)...")
        time.sleep(2.5)

        print(f"[*] STEP 3: Attempting to access target: {url}")
        # Update Referer to look like we clicked from the home page
        client.headers.update({"Referer": "https://www.imot.bg/"})
        
        resp = client.get(url)
        content = resp.content.decode('windows-1251', errors='replace')

        if any(term in content.lower() for term in ["captcha", "robot", "security check"]):
            print("!!! [FAIL] Still Blocked by WAF. They require JavaScript execution. !!!")
            
            # Save the failure page to see what the challenge looks like
            with open("waf_challenge.html", "w", encoding="utf-8") as f:
                f.write(content)
            print("[i] Challenge page saved to waf_challenge.html. Check if it's Cloudflare or internal.")
            return

        print(f"[SUCCESS] Content Length: {len(content)} chars")
        
        soup = BeautifulSoup(content, 'html.parser')
        title = soup.find('title')
        print(f"[+] Listing Title: {title.text.strip() if title else 'N/A'}")

        # Look for the price to confirm success
        price = soup.find(id='price_obs')
        if price:
            print(f"[!!!] PRICE DETECTED: {price.text.strip()}")
        else:
            print("[?] Price tag not found. Listing might be hidden in script tags.")

if __name__ == "__main__":
    bypass_audit("https://www.imot.bg/pcgi/imot.cgi?act=5&adv=1c171899111")


=========================================
FILE: ./waf_challenge.html
=========================================
<!DOCTYPE html>
    <html lang="bg">
      <head>
        <title>Ð˜Ð¼Ð¾Ñ‚Ð¸ - Imot.bg - ÐŸÐ°Ð·Ð°Ñ€ÑŠÑ‚ Ð½Ð° Ð½ÐµÐ´Ð²Ð¸Ð¶Ð¸Ð¼Ð¸ Ð¸Ð¼Ð¾Ñ‚Ð¸ - Ð¿Ñ€Ð¾Ð´Ð°Ð¶Ð±Ð¸, Ð½Ð°ÐµÐ¼Ð¸, Ð°Ð³ÐµÐ½Ñ†Ð¸Ð¸, Ð½Ð¾Ð²Ð¸Ð½Ð¸ Ð·Ð° Ð¸Ð¼Ð¾Ñ‚Ð¸ (imoti)</title>
        <meta http-equiv="Content-Type" content="text/html; charset=windows-1251">
        <meta name="description" content="imot.bg - ÐŸÐ°Ð·Ð°Ñ€ÑŠÑ‚ Ð½Ð° Ð½ÐµÐ´Ð²Ð¸Ð¶Ð¸Ð¼Ð¸ Ð¸Ð¼Ð¾Ñ‚Ð¸ Ð² Ð‘ÑŠÐ»Ð³Ð°Ñ€Ð¸Ñ. ÐžÑ„ÐµÑ€Ñ‚Ð¸ Ð·Ð° Ð¿Ñ€Ð¾Ð´Ð°Ð¶Ð±Ð°, Ð¿Ð¾Ð´ Ð½Ð°ÐµÐ¼, ÐºÑƒÐ¿ÑƒÐ²Ð°, Ð½Ð°ÐµÐ¼Ð°, Ð·Ð°Ð¼ÐµÐ½Ñ. ÐÐ³ÐµÐ½Ñ†Ð¸Ð¸ Ð·Ð° Ð¸Ð¼Ð¾Ñ‚Ð¸. ÐÐ¾Ð²Ð¸Ð½Ð¸. Ð¡ÑŠÐ²ÐµÑ‚Ð¸. Ð¡Ñ‚Ñ€Ð¾Ð¸Ñ‚ÐµÐ»ÑÑ‚Ð²Ð¾. ÐžÐ±Ð·Ð°Ð²ÐµÐ¶Ð´Ð°Ð½Ðµ. Ð˜Ð½Ñ‚ÐµÑ€Ð¸Ð¾Ñ€. ÐšÑ€ÐµÐ´Ð¸Ñ‚Ð¸Ñ€Ð°Ð½Ðµ Ð¸ Ð´Ñ€.">
        <link rel="SHORTCUT ICON" href="https://www.imot.bg/favicon.ico"/>
        <link rel="stylesheet" href="/styless/styles.css?633" type="text/css">
        
                <script type="text/javascript" charset="UTF-8" src="//cdn.cookie-script.com/s/5874e0489319507715f52b3fd38d9a7a.js"></script>
        <script type="text/javascript" src="/jss/scripts.js?633"></script>
        <script type="text/javascript" src="/jss/dim.js?633"></script>
        <script type="text/javascript" src="/jss/mobile-detect.min.js?633"></script>
        <script type="text/javascript" src="/jss/jquery.min.js"></script>
        <script type="text/javascript">
        
        
        </script>
        
<script type="text/javascript" src="/jss/ac_runactivecontent.js"></script>
<script type="text/javascript" src="/jss/scriptsJquery.js"></script>
        <script>(function(){/*

 Copyright The Closure Library Authors.
 SPDX-License-Identifier: Apache-2.0
*/
'use strict';var g=function(a){var b=0;return function(){return b<a.length?{done:!1,value:a[b++]}:{done:!0}}},l=this||self,m=/^[\w+/_-]+[=]{0,2}$/,p=null,q=function(){},r=function(a){var b=typeof a;if("object"==b)if(a){if(a instanceof Array)return"array";if(a instanceof Object)return b;var c=Object.prototype.toString.call(a);if("[object Window]"==c)return"object";if("[object Array]"==c||"number"==typeof a.length&&"undefined"!=typeof a.splice&&"undefined"!=typeof a.propertyIsEnumerable&&!a.propertyIsEnumerable("splice"))return"array";
if("[object Function]"==c||"undefined"!=typeof a.call&&"undefined"!=typeof a.propertyIsEnumerable&&!a.propertyIsEnumerable("call"))return"function"}else return"null";else if("function"==b&&"undefined"==typeof a.call)return"object";return b},u=function(a,b){function c(){}c.prototype=b.prototype;a.prototype=new c;a.prototype.constructor=a};var v=function(a,b){Object.defineProperty(l,a,{configurable:!1,get:function(){return b},set:q})};var y=function(a,b){this.b=a===w&&b||"";this.a=x},x={},w={};var aa=function(a,b){a.src=b instanceof y&&b.constructor===y&&b.a===x?b.b:"type_error:TrustedResourceUrl";if(null===p)b:{b=l.document;if((b=b.querySelector&&b.querySelector("script[nonce]"))&&(b=b.nonce||b.getAttribute("nonce"))&&m.test(b)){p=b;break b}p=""}b=p;b&&a.setAttribute("nonce",b)};var z=function(){return Math.floor(2147483648*Math.random()).toString(36)+Math.abs(Math.floor(2147483648*Math.random())^+new Date).toString(36)};var A=function(a,b){b=String(b);"application/xhtml+xml"===a.contentType&&(b=b.toLowerCase());return a.createElement(b)},B=function(a){this.a=a||l.document||document};B.prototype.appendChild=function(a,b){a.appendChild(b)};var C=function(a,b,c,d,e,f){try{var k=a.a,h=A(a.a,"SCRIPT");h.async=!0;aa(h,b);k.head.appendChild(h);h.addEventListener("load",function(){e();d&&k.head.removeChild(h)});h.addEventListener("error",function(){0<c?C(a,b,c-1,d,e,f):(d&&k.head.removeChild(h),f())})}catch(n){f()}};var ba=l.atob("aHR0cHM6Ly93d3cuZ3N0YXRpYy5jb20vaW1hZ2VzL2ljb25zL21hdGVyaWFsL3N5c3RlbS8xeC93YXJuaW5nX2FtYmVyXzI0ZHAucG5n"),ca=l.atob("WW91IGFyZSBzZWVpbmcgdGhpcyBtZXNzYWdlIGJlY2F1c2UgYWQgb3Igc2NyaXB0IGJsb2NraW5nIHNvZnR3YXJlIGlzIGludGVyZmVyaW5nIHdpdGggdGhpcyBwYWdlLg=="),da=l.atob("RGlzYWJsZSBhbnkgYWQgb3Igc2NyaXB0IGJsb2NraW5nIHNvZnR3YXJlLCB0aGVuIHJlbG9hZCB0aGlzIHBhZ2Uu"),ea=function(a,b,c){this.b=a;this.f=new B(this.b);this.a=null;this.c=[];this.g=!1;this.i=b;this.h=c},F=function(a){if(a.b.body&&!a.g){var b=
function(){D(a);l.setTimeout(function(){return E(a,3)},50)};C(a.f,a.i,2,!0,function(){l[a.h]||b()},b);a.g=!0}},D=function(a){for(var b=G(1,5),c=0;c<b;c++){var d=H(a);a.b.body.appendChild(d);a.c.push(d)}b=H(a);b.style.bottom="0";b.style.left="0";b.style.position="fixed";b.style.width=G(100,110).toString()+"%";b.style.zIndex=G(2147483544,2147483644).toString();b.style["background-color"]=I(249,259,242,252,219,229);b.style["box-shadow"]="0 0 12px #888";b.style.color=I(0,10,0,10,0,10);b.style.display=
"flex";b.style["justify-content"]="center";b.style["font-family"]="Roboto, Arial";c=H(a);c.style.width=G(80,85).toString()+"%";c.style.maxWidth=G(750,775).toString()+"px";c.style.margin="24px";c.style.display="flex";c.style["align-items"]="flex-start";c.style["justify-content"]="center";d=A(a.f.a,"IMG");d.className=z();d.src=ba;d.style.height="24px";d.style.width="24px";d.style["padding-right"]="16px";var e=H(a),f=H(a);f.style["font-weight"]="bold";f.textContent=ca;var k=H(a);k.textContent=da;J(a,
e,f);J(a,e,k);J(a,c,d);J(a,c,e);J(a,b,c);a.a=b;a.b.body.appendChild(a.a);b=G(1,5);for(c=0;c<b;c++)d=H(a),a.b.body.appendChild(d),a.c.push(d)},J=function(a,b,c){for(var d=G(1,5),e=0;e<d;e++){var f=H(a);b.appendChild(f)}b.appendChild(c);c=G(1,5);for(d=0;d<c;d++)e=H(a),b.appendChild(e)},G=function(a,b){return Math.floor(a+Math.random()*(b-a))},I=function(a,b,c,d,e,f){return"rgb("+G(Math.max(a,0),Math.min(b,255)).toString()+","+G(Math.max(c,0),Math.min(d,255)).toString()+","+G(Math.max(e,0),Math.min(f,
255)).toString()+")"},H=function(a){a=A(a.f.a,"DIV");a.className=z();return a},E=function(a,b){0>=b||null!=a.a&&0!=a.a.offsetHeight&&0!=a.a.offsetWidth||(fa(a),D(a),l.setTimeout(function(){return E(a,b-1)},50))},fa=function(a){var b=a.c;var c="undefined"!=typeof Symbol&&Symbol.iterator&&b[Symbol.iterator];b=c?c.call(b):{next:g(b)};for(c=b.next();!c.done;c=b.next())(c=c.value)&&c.parentNode&&c.parentNode.removeChild(c);a.c=[];(b=a.a)&&b.parentNode&&b.parentNode.removeChild(b);a.a=null};var ia=function(a,b,c,d,e){var f=ha(c),k=function(n){n.appendChild(f);l.setTimeout(function(){f?(0!==f.offsetHeight&&0!==f.offsetWidth?b():a(),f.parentNode&&f.parentNode.removeChild(f)):a()},d)},h=function(n){document.body?k(document.body):0<n?l.setTimeout(function(){h(n-1)},e):b()};h(3)},ha=function(a){var b=document.createElement("div");b.className=a;b.style.width="1px";b.style.height="1px";b.style.position="absolute";b.style.left="-10000px";b.style.top="-10000px";b.style.zIndex="-10000";return b};var K={},L=null;var M=function(){},N="function"==typeof Uint8Array,O=function(a,b){a.b=null;b||(b=[]);a.j=void 0;a.f=-1;a.a=b;a:{if(b=a.a.length){--b;var c=a.a[b];if(!(null===c||"object"!=typeof c||Array.isArray(c)||N&&c instanceof Uint8Array)){a.g=b-a.f;a.c=c;break a}}a.g=Number.MAX_VALUE}a.i={}},P=[],Q=function(a,b){if(b<a.g){b+=a.f;var c=a.a[b];return c===P?a.a[b]=[]:c}if(a.c)return c=a.c[b],c===P?a.c[b]=[]:c},R=function(a,b,c){a.b||(a.b={});if(!a.b[c]){var d=Q(a,c);d&&(a.b[c]=new b(d))}return a.b[c]};
M.prototype.h=N?function(){var a=Uint8Array.prototype.toJSON;Uint8Array.prototype.toJSON=function(){var b;void 0===b&&(b=0);if(!L){L={};for(var c="ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789".split(""),d=["+/=","+/","-_=","-_.","-_"],e=0;5>e;e++){var f=c.concat(d[e].split(""));K[e]=f;for(var k=0;k<f.length;k++){var h=f[k];void 0===L[h]&&(L[h]=k)}}}b=K[b];c=[];for(d=0;d<this.length;d+=3){var n=this[d],t=(e=d+1<this.length)?this[d+1]:0;h=(f=d+2<this.length)?this[d+2]:0;k=n>>2;n=(n&
3)<<4|t>>4;t=(t&15)<<2|h>>6;h&=63;f||(h=64,e||(t=64));c.push(b[k],b[n],b[t]||"",b[h]||"")}return c.join("")};try{return JSON.stringify(this.a&&this.a,S)}finally{Uint8Array.prototype.toJSON=a}}:function(){return JSON.stringify(this.a&&this.a,S)};var S=function(a,b){return"number"!==typeof b||!isNaN(b)&&Infinity!==b&&-Infinity!==b?b:String(b)};M.prototype.toString=function(){return this.a.toString()};var T=function(a){O(this,a)};u(T,M);var U=function(a){O(this,a)};u(U,M);var ja=function(a,b){this.c=new B(a);var c=R(b,T,5);c=new y(w,Q(c,4)||"");this.b=new ea(a,c,Q(b,4));this.a=b},ka=function(a,b,c,d){b=new T(b?JSON.parse(b):null);b=new y(w,Q(b,4)||"");C(a.c,b,3,!1,c,function(){ia(function(){F(a.b);d(!1)},function(){d(!0)},Q(a.a,2),Q(a.a,3),Q(a.a,1))})};var la=function(a,b){V(a,"internal_api_load_with_sb",function(c,d,e){ka(b,c,d,e)});V(a,"internal_api_sb",function(){F(b.b)})},V=function(a,b,c){a=l.btoa(a+b);v(a,c)},W=function(a,b,c){for(var d=[],e=2;e<arguments.length;++e)d[e-2]=arguments[e];e=l.btoa(a+b);e=l[e];if("function"==r(e))e.apply(null,d);else throw Error("API not exported.");};var X=function(a){O(this,a)};u(X,M);var Y=function(a){this.h=window;this.a=a;this.b=Q(this.a,1);this.f=R(this.a,T,2);this.g=R(this.a,U,3);this.c=!1};Y.prototype.start=function(){ma();var a=new ja(this.h.document,this.g);la(this.b,a);na(this)};
var ma=function(){var a=function(){if(!l.frames.googlefcPresent)if(document.body){var b=document.createElement("iframe");b.style.display="none";b.style.width="0px";b.style.height="0px";b.style.border="none";b.style.zIndex="-1000";b.style.left="-1000px";b.style.top="-1000px";b.name="googlefcPresent";document.body.appendChild(b)}else l.setTimeout(a,5)};a()},na=function(a){var b=Date.now();W(a.b,"internal_api_load_with_sb",a.f.h(),function(){var c;var d=a.b,e=l[l.btoa(d+"loader_js")];if(e){e=l.atob(e);
e=parseInt(e,10);d=l.btoa(d+"loader_js").split(".");var f=l;d[0]in f||"undefined"==typeof f.execScript||f.execScript("var "+d[0]);for(;d.length&&(c=d.shift());)d.length?f[c]&&f[c]!==Object.prototype[c]?f=f[c]:f=f[c]={}:f[c]=null;c=Math.abs(b-e);c=1728E5>c?0:c}else c=-1;0!=c&&(W(a.b,"internal_api_sb"),Z(a,Q(a.a,6)))},function(c){Z(a,c?Q(a.a,4):Q(a.a,5))})},Z=function(a,b){a.c||(a.c=!0,a=new l.XMLHttpRequest,a.open("GET",b,!0),a.send())};(function(a,b){l[a]=function(c){for(var d=[],e=0;e<arguments.length;++e)d[e-0]=arguments[e];l[a]=q;b.apply(null,d)}})("__d3lUW8vwsKlB__",function(a){"function"==typeof window.atob&&(a=window.atob(a),a=new X(a?JSON.parse(a):null),(new Y(a)).start())});}).call(this);

window.__d3lUW8vwsKlB__("WyI0YTBhODk3MmZlNzIwMDgwIixbbnVsbCxudWxsLG51bGwsImh0dHBzOi8vZnVuZGluZ2Nob2ljZXNtZXNzYWdlcy5nb29nbGUuY29tL2YvQUdTS1d4VWhqXzdlWWM2MzVYbk5ZTkgteWdXaEZTOXRDdmh5S21va1pQQkNyTkRBX2YwdUNYSTFweHJSQk9fdjBkVlB1cUJPb3kxaDg1YXlzd01rOVZKSVRmd1x1MDAzZCJdCixbMjAsImRpdi1ncHQtYWQiLDEwMCwiTkdFd1lUZzVOekptWlRjeU1EQTRNQVx1MDAzZFx1MDAzZCIsW251bGwsbnVsbCxudWxsLCJodHRwczovL3d3dy5nc3RhdGljLmNvbS8wZW1uL2YvcC80YTBhODk3MmZlNzIwMDgwLmpzP3VzcXBcdTAwM2RDQTAiXQpdCiwiaHR0cHM6Ly9mdW5kaW5nY2hvaWNlc21lc3NhZ2VzLmdvb2dsZS5jb20vbC9BR1NLV3hXTmFTeEhpaVBkOURldjdGWl9ZbUNpSklOQmVmQjQ4WkJ5VVc2eG5XTnJGcWQ3OXRGVmlsZEt3Ti12ZTlLX254eUVBT19FUF9wQWNsdEFfTlF0P2FiXHUwMDNkMSIsImh0dHBzOi8vZnVuZGluZ2Nob2ljZXNtZXNzYWdlcy5nb29nbGUuY29tL2wvQUdTS1d4WEdqdFhkREs5NW13RXAwajhnOGZ4eDlLZmtpNDlsSTJrdmxXTzJxaFZhZ2hIXy1YNWtnUml6aF9FZW1xZW9HN0RJNmE3SDZoLVVCMUd3ZTdBZT9hYlx1MDAzZDJcdTAwMjZzYmZcdTAwM2QxIiwiaHR0cHM6Ly9mdW5kaW5nY2hvaWNlc21lc3NhZ2VzLmdvb2dsZS5jb20vbC9BR1NLV3hXRmktTGk1cjBoeGljcDJkOGN1aUlWMGQ2MTUxZ0ZtbGVWLS1nTjdaSnB3ZTgyMVFsY0RkNjlleW8xck1PMjVQQl8zU2x2c2plWWhyMVRxVEZ1P3NiZlx1MDAzZDIiXQo=");</script>
        <script defer async src="https://www.googletagmanager.com/gtag/js?id=G-0LZF32451N"></script>
        <script>
        const gtagLoaded = new Event('gtag-loaded');(function(d, s, id){var js, fjs = d.getElementsByTagName(s)[0];if (d.getElementById(id)) {return;}js = d.createElement(s);js.id = id;js.defer = true;js.async = true;js.src = "https://www.googletagmanager.com/gtag/js?id=G-0LZF32451N";js.onload = function(){document.dispatchEvent(gtagLoaded);};fjs.parentNode.insertBefore(js, fjs);}(document, 'script', 'gtag-js'));try {window.dataLayer = window.dataLayer || [];function gtag(){dataLayer.push(arguments);}gtag('js', new Date());gtag('config', 'G-0LZF32451N');gtag('config', 'UA-1160575-1');}catch(error){}
        </script>

        <script async="async" src="https://www.googletagservices.com/tag/js/gpt.js"></script>
        <script>
          var googletag = googletag || {};
          googletag.cmd = googletag.cmd || [];
        </script>
        <script>
          googletag.cmd.push(function() {
            googletag.pubads().set("adsense_background_color", "FFFFFF");
          });
        </script>
        <script>
        googletag.cmd.push(function() {
          

          googletag.pubads().enableSingleRequest();
          googletag.enableServices();
        });
        </script>

      </head>
      <body onload="javascript: if(window.startw)startw();">

      
      <div class="imotPhotosIframe" id="imotPhotos"></div>

      <div style="text-align:left; z-index:1; position:relative; margin: 0 auto 10px auto; width:980px; cursor:auto;">
      


  <div class="regWindow" id="langWindow">
    <div class="panel" style="width:700px; left: 0">
      <div class="formVhod shareWindow" style="border-radius:10px;width:700px;">
        <a href="javascript:closLangWindow();" class="close" title="Ð—Ð°Ñ‚Ð²Ð¾Ñ€Ð¸" style="margin-left:645px;"></a>
        <div class="price-stat">
          <div class="shareOptions" style="width:660px">
            <div class="boxTITLE">Translations in other languages:</div>
            <div class="TITLE">
              All real estate ads published on <span style="color: #900;">imot.bg</span> have been translated into English and published on the partner site
              <br>
              <img src="//www.imot.bg/images/picturess/icons/imoti-info-logo.svg" style="margin-top: 12px; height: 38px;">
            </div>

            <div class="screen1">
              <div class="emailGrid" style="grid-gap:0">
                <div class="C4">
                  <a href="https://imoti.info/en" class="send gotoSite" target="_blank" onclick="closLangWindow();">Continue</a>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>

<script type="module">
                        import { initializeApp } from "https://www.gstatic.com/firebasejs/9.6.6/firebase-app.js";
                        import { onMessage, isSupported, getMessaging } from "https://www.gstatic.com/firebasejs/9.6.6/firebase-messaging.js";

                        isSupported().then((isSuppored) => {
                          if (isSuppored) {
                            var fcm=getcookieval('fcm');
                            try {
                              fcm = JSON.parse(decodeURIComponent(fcm));
                            } catch (err) {
                              fcm = {};
                            }

                            if (fcm.status == 'agree')
                              receiveFCM();

                            function receiveFCM() {

                              initializeApp({ apiKey: "AIzaSyDl3rtJjr6tZw0gJrtZlECkn8L0rWWVaRA",
                                authDomain: "imot-466de.firebaseapp.com",
                                databaseURL: "https://imot-466de.firebaseio.com",
                                projectId: "imot-466de",
                                storageBucket: "imot-466de.appspot.com",
                                messagingSenderId: "647267607875",
                                appId: "1:647267607875:web:1bef151e4da339c07b3bf6"
                              });

                              const messaging = getMessaging();
                              onMessage(messaging, (payload) => {

                                if (payload && payload.data && payload.data.type === 'newadv')
                                  {
                                    document.getElementById('notification-popup').style.display='block';
                                    document.getElementById('notification-popup').style.opacity='1';
                                    document.getElementById('notification-popup-bodyonly').innerHTML = payload.data.bodyonly;
                                    document.getElementById('notification-popup-bodyonly').href = payload.data.url;
                                    document.getElementById('notification-popup-span-price').innerHTML = payload.data.price;
                                    document.getElementById('notification-popup-area').innerHTML = payload.data.area;
                                    document.getElementById('notification-popup-town').innerHTML = payload.data.town;
                                    document.getElementById('notification-popup-href-img').href = payload.data.url;

                                    if (payload.data.image)
                                      {
                                        document.getElementById('notification-popup-img').src = payload.notification.image;
                                        document.getElementById('notification-popup-img').alt = payload.data.bodyonly;
                                      }
                                  }
                                else if (payload && payload.data && payload.data.type === 'newprice')
                                  {
                                    document.getElementById('notification-popup-price').style.display='block';
                                    document.getElementById('notification-popup-price').style.opacity='1';

                                    document.getElementById('notification-popup-price-bodyonly').innerHTML = payload.data.advinfo;
                                    document.getElementById('notification-popup-price-bodyonly').href = payload.data.url;
                                    document.getElementById('notification-popup-price-old').innerHTML = payload.data.old_price;
                                    document.getElementById('notification-popup-price-new').innerHTML = payload.data.new_price;
                                    document.getElementById('notification-popup-price-href-img').href = payload.data.url;

                                    if (payload.notification.image)
                                      {
                                        document.getElementById('notification-popup-price-img').src = payload.notification.image;
                                        document.getElementById('notification-popup-price-img').alt = payload.data.advinfo;
                                      }
                                  }
                              });
                           }

                           function closeNotification() {
                             document.getElementById('notification-popup').style.display='none';
                             document.getElementById('notification-popup-price').style.display='none';
                           }

                           window.closeNotification = closeNotification;
                          }
                        })
                     </script>
                     <div class="logPopup" id="notification-popup">
                       <div class="newLogin" style="width:520px;padding-top:0;">
                         <a href="javascript:closeNotification();" class="close" style="position: relative; left:435px; top:40px;"></a>
                         <div class="formsWrapper">
                           <div style="font-size:14px; display:block; border-bottom:1px solid #b01110; font-weight:bold; margin-bottom:15px; padding-bottom:5px; width:94%; height: 25px;">
                             ÐŸÐ¾Ð»ÑƒÑ‡Ð¸Ñ…Ñ‚Ðµ Ð½Ð¾Ð²Ð° Ð¾Ð±ÑÐ²Ð° Ð¿Ð¾ Ñ„Ð¸Ð»Ñ‚ÑŠÑ€
                           </div>

                           <a href="" class="photoLink" style="float: left;" id="notification-popup-href-img" onclick="closeNotification();">
                             <img src="../images/picturess/nophoto_490x341.svg" style="object-fit: cover; max-width: 120px; max-height: 100px;" class="noborder" id="notification-popup-img" alt="">
                           </a>

                           <div style="font-size:14px; float: right; width:290px; white-space: nowrap; word-break: break-all; text-overflow: ellipsis; overflow: hidden;">
                             <a href="" style="text-decoration: underline;font-size: 14px;font-weight: bold;color: #000;" id="notification-popup-bodyonly" onclick="closeNotification();"></a><br/><br>
                             <strong style="color: #b01110;" id="notification-popup-span-price"></strong><br/>
                             <span id="notification-popup-area"></span><br/>
                             <span id="notification-popup-town"></span><br/>
                           </div>
                           <div style="clear: both;"></div>
                         </div>
                       </div>
                     </div>

                     <div class="logPopup" id="notification-popup-price" style="">
                       <div class="newLogin" style="width:520px;padding-top:0;">
                         <a href="javascript:closeNotification();" class="close" style="position: relative; left:435px; top:40px;"></a>
                         <div class="formsWrapper">
                           <div style="font-size:14px; display:block; border-bottom:1px solid #b01110; font-weight:bold; margin-bottom:15px; padding-bottom:5px; width:94%; height: 25px;">
                             ÐŸÑ€Ð¾Ð¼ÑÐ½Ð° Ð½Ð° Ñ†ÐµÐ½Ð° Ð½Ð° Ð½Ð°Ð±Ð»ÑŽÐ´Ð°Ð²Ð°Ð½Ð° Ð¾Ð±ÑÐ²Ð°
                           </div>

                           <a href="" class="photoLink" style="float: left;" id="notification-popup-price-href-img" onclick="closeNotification();">
                             <img src="../images/picturess/nophoto_490x341.svg" style="object-fit: cover; max-width: 120px; max-height: 100px;" class="noborder" id="notification-popup-price-img" alt="">
                           </a>

                           <div style="font-size:14px; float: right; width:290px">
                             <a href="" style="text-decoration: underline;font-size: 14px;font-weight: bold;color: #000;" id="notification-popup-price-bodyonly"></a><br/><br>

                             ÑÑ‚Ð°Ñ€Ð° Ñ†ÐµÐ½Ð° <span style="color: #b01110;" id="notification-popup-price-old"></span> <br/>
                             Ð½Ð¾Ð²Ð° Ñ†ÐµÐ½Ð° <strong style="color: #b01110;" id="notification-popup-price-new"></strong>
                           </div>
                           <div style="clear: both;"></div>
                         </div>
                       </div>
                     </div>


  <div class="header">
    <a href="//www.imot.bg" class="left" style="text-decoration:none;">
      <img src="//www.imot.bg/images/picturess/logo.svg" style="width:212px; height:65px;" alt="imot.bg â€“ Ð¾Ð±ÑÐ²Ð¸ Ð·Ð° Ð¿Ñ€Ð¾Ð´Ð°Ð¶Ð±Ð¸ Ð¸ Ð½Ð°ÐµÐ¼Ð¸ Ð½Ð° Ð¸Ð¼Ð¾Ñ‚Ð¸">
      <div class="iSlogan">Ð¡Ð°Ð¹Ñ‚ Ð·Ð° Ð¸Ð¼Ð¾Ñ‚Ð¸ <strong>â„–1</strong></div>
    </a>
    <div id="logtable2" class="right">
      
  
  <div class="regWindow" id="langWindow">
    <div class="panel" style="width:700px; left: 0">
      <div class="formVhod shareWindow" style="border-radius:10px;width:700px;">
        <a href="javascript:closLangWindow();" class="close" title="Ð—Ð°Ñ‚Ð²Ð¾Ñ€Ð¸" style="margin-left:645px;"></a>
        <div class="price-stat">
          <div class="shareOptions" style="width:660px">
            <div class="boxTITLE">Translations in other languages:</div>
            <div class="TITLE">
              All real estate ads published on <span style="color: #900;">imot.bg</span> have been translated into English and published on the partner site
              <br>
              <img src="//www.imot.bg/images/picturess/icons/imoti-info-logo.svg" style="margin-top: 12px; height: 38px;">
            </div>

            <div class="screen1">
              <div class="emailGrid" style="grid-gap:0">
                <div class="C4">
                  <a href="https://imoti.info/en" class="send gotoSite" target="_blank" onclick="closLangWindow();">Continue</a>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
  <div class="logPopup" id="logpopup"></div>
  <a class="flagBtn" onclick="ShowLangWindow();"><img src="//www.imot.bg/images/picturess/icons/flag-en.svg"></a>
  <a data-link="//www.imot.bg/pcgi/imot.cgi?act=1" class="clever-link addButton"><img src="//www.imot.bg/images/picturess/plus.svg"> Ð”ÐžÐ‘ÐÐ’Ð˜ ÐžÐ‘Ð¯Ð’Ð</a>
  
      <a data-link="//www.imot.bg/pcgi/imot.cgi?act=26&rub=0" class="clever-link editButton">Ð ÐµÐ´Ð°ÐºÑ†Ð¸Ñ Ð½Ð° Ð¾Ð±ÑÐ²Ð°</a>
      <div class="loginLinks">
        <span class="logIn">
          <a href="//www.imot.bg/pcgi/imot.cgi?act=26&logact=1"><strong>Ð’Ñ…Ð¾Ð´</strong></a> | <a href="//www.imot.bg/pcgi/imot.cgi?act=26&logact=2">ÐÐ¾Ð²Ð° Ð ÐµÐ³Ð¸ÑÑ‚Ñ€Ð°Ñ†Ð¸Ñ</a>
        </span>
      </div>
      
  
  
    </div>
  </div>
  <div class="iMenu">
    <a href="//www.imot.bg" class="">ÐÐ°Ñ‡Ð°Ð»Ð¾</a>
    <a href="//www.imot.bg/pcgi/imot.cgi?act=1" class="">ÐŸÑƒÐ±Ð»Ð¸ÐºÑƒÐ²Ð°Ð½Ðµ</a>
    <a href="//www.imot.bg/search" class="selected">Ð¢ÑŠÑ€ÑÐµÐ½Ðµ</a>
    <a href="//www.imot.bg/pcgi/imot.cgi?act=7" class="">ÐÐ¾Ð²Ð¸ ÑÐ³Ñ€Ð°Ð´Ð¸</a>
    <a href="//www.imot.bg/agentsii" class="">ÐÐ³ÐµÐ½Ñ†Ð¸Ð¸</a>
    <a href="https://fakti.bg" target="_blank">ÐÐ¾Ð²Ð¸Ð½Ð¸</a>
    <a href="https://creditcenter.bg/buy-new-home" target="_blank">ÐšÑ€ÐµÐ´Ð¸Ñ‚Ð¸</a>
    <div class="imimmore">
      <a href="//www.imot.bg/more-services" class="oshte ">+ ÐžÑ‰Ðµ...</a>
      <div class="down-menu">
        <a href="//www.imot.bg/sredni-ceni" class="sredni">Ð¡Ñ€ÐµÐ´Ð½Ð¸ Ñ†ÐµÐ½Ð¸ Ð½Ð° Ð¸Ð¼Ð¾Ñ‚Ð¸Ñ‚Ðµ</a>
        <a href="//www.imot.bg/ocenka-na-imot" class="kolko">ÐšÐ¾Ð»ÐºÐ¾ ÑÑ‚Ñ€ÑƒÐ²Ð° Ð¼Ð¾ÑÑ‚ Ð¸Ð¼Ð¾Ñ‚?</a>
        <a data-link="//www.imot.bg/searcharch" class="clever-link arhivni" style="cursor:pointer;">ÐÑ€Ñ…Ð¸Ð²Ð½Ð¸ Ð´Ð°Ð½Ð½Ð¸</a>
        <a href="//www.imot.bg/imoti-s-padashti-ceni" class="padashti">Ð˜Ð¼Ð¾Ñ‚Ð¸ Ñ Ð¿Ð°Ð´Ð°Ñ‰Ð¸ Ñ†ÐµÐ½Ð¸</a>
      </div>
    </div>
    <span id="logtable3"><a href="//www.imot.bg/pcgi/imot.cgi?act=26" class="right">ÐœÐ¾ÑÑ‚ Ð¸Ð¼Ð¾Ñ‚</a></span>
    <div class="bottomLine"></div>
  </div>
  




  <div class="pageMessageAlert page980 MT20">
    Ð¢ÑŠÑ€ÑÐµÐ½Ð°Ñ‚Ð° Ð¾Ñ‚ Ð’Ð°Ñ Ð¾Ð±ÑÐ²Ð° Ðµ Ð¸Ð·Ñ‚Ñ€Ð¸Ñ‚Ð° Ð¸Ð»Ð¸ Ð½Ðµ Ðµ Ð°ÐºÑ‚Ð¸Ð²Ð½Ð°.
  </div>
  <div class="width980px margincent">
    <div class="center m-t-20 m-b-20" style="font-size: 18px;">ÐœÐ¾Ð»Ñ Ñ€Ð°Ð·Ð³Ð»eÐ´Ð°Ð¹Ñ‚Ðµ Ð½Ð°Ð¹-Ð½Ð¾Ð²Ð¸Ñ‚Ðµ Ð¿Ð¾Ð´Ð¾Ð±Ð½Ð¸ Ð¾Ð±ÑÐ²Ð¸, Ð¿ÑƒÐ±Ð»Ð¸ÐºÑƒÐ²Ð°Ð½Ð¸ Ð¿Ñ€ÐµÐ· Ð¿Ð¾ÑÐ»ÐµÐ´Ð½Ð¸Ñ‚Ðµ 24 Ñ‡Ð°ÑÐ° Ð² imot.bg</div>
  </div>
  <div class="ads2023">
    
  </div>




  <div class="seoBox" id="seoBox" style="margin:0">
                   
                 </div>
  <div style="width:100%; margin-top:10px; text-align: right;">
    <a href="//www.imot.bg/contacts" class="footLinks1" style="font-weight:normal; color:#900; text-decoration:underline;">Ð’ÑŠÐ¿Ñ€Ð¾ÑÐ¸ Ð¸ Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ ÐºÑŠÐ¼ imot.bg</a>
  </div>
  <div style="width:100%; margin-top:10px;">
    <a href="//www.imot.bg/contacts" class="footLinks1">ÐšÐžÐÐ¢ÐÐšÐ¢Ð˜</a> |
    <a href="//www.imot.bg/pcgi/imot.cgi?act=12" class="footLinks1">SMS ÐšÐžÐ”ÐžÐ’Ð•</a> |
    <a href="//www.imot.bg/help" class="footLinks1">ÐŸÐžÐœÐžÐ©</a> |
    <a href="//www.imot.bg/obshti-uslovia" class="footLinks1">ÐžÐ‘Ð©Ð˜ Ð£Ð¡Ð›ÐžÐ’Ð˜Ð¯</a> |
    <a href="https://rezonmedia.bg/tarifi/imot" class="footLinks1" target="_blank">Ð Ð•ÐšÐ›ÐÐœÐ</a> |
    <a href="//www.imot.bg/zashtita-na-lichni-danni" class="footLinks1">Ð—ÐÐ©Ð˜Ð¢Ð ÐÐ Ð›Ð˜Ð§ÐÐ˜Ð¢Ð• Ð”ÐÐÐÐ˜</a> |
    <a href="//www.imot.bg/sitemap" class="footLinks1">ÐšÐÐ Ð¢Ð ÐÐ Ð¡ÐÐ™Ð¢Ð</a> |
  </div>
  <div style="margin-top:10px; background-color: #900; color:#FFF; padding-left:10px; height:26px; line-height:26px;">
    <a href="https://rezonmedia.bg" target="_blank" class="footLinks2">Ð ÐµÐ·Ð¾Ð½ ÐœÐµÐ´Ð¸Ñ</a> |
    <a href="//www.imot.bg" target="_blank" class="footLinks2">Ð˜Ð¼Ð¾Ñ‚Ð¸</a> |
    <a href="http://www.mobile.bg" target="_blank" class="footLinks2">ÐÐ²Ñ‚Ð¾Ð¼Ð¾Ð±Ð¸Ð»Ð¸</a> |
    <a href="https://www.zaplata.bg" target="_blank" class="footLinks2" title="ÐžÐ±ÑÐ²Ð¸ Ð·Ð° Ñ€Ð°Ð±Ð¾Ñ‚Ð° Ð² Ð‘ÑŠÐ»Ð³Ð°Ñ€Ð¸Ñ Ð¸ Ñ‡ÑƒÐ¶Ð±Ð¸Ð½Ð°">Ð Ð°Ð±Ð¾Ñ‚Ð°</a> |
    <a href="https://www.fakti.bg" target="_blank" class="footLinks2" title="Ð¡ÑŠÐ±Ð¸Ñ‚Ð¸Ñ Ð¾Ñ‚ Ð‘ÑŠÐ»Ð³Ð°Ñ€Ð¸Ñ Ð¸ ÑÐ²ÐµÑ‚Ð°">ÐÐ¾Ð²Ð¸Ð½Ð¸</a> |
    <a href="https://bazar.bg" target="_blank" class="footLinks2">ÐžÐ±ÑÐ²Ð¸</a> |
    <a href="https://prevodirezon.bg" target="_blank" class="footLinks2">ÐŸÑ€ÐµÐ²Ð¾Ð´Ð¸ Ð¸ Ð»ÐµÐ³Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ</a>
    <span style="float: right; margin-right:5px;">2002-2025 &reg;  Copyright imot.bg</span>
  </div>
  <div id="mob_version" style="width:100%; text-align:center;"></div>
  <script>
    var mvc=getCookie('full');
    var mvd=document.getElementById("mob_version");
    if ( mvd && (mvc==1) )
      mvd.innerHTML='<br><a href="https://m.imot.bg" class="footLinks1" onclick="document.cookie=\'full=0; expires=Thu, 01 Jan 1970 00:00:01 GMT; path=/; domain=.imot.bg\'"><u>ÐœÐ¾Ð±Ð¸Ð»Ð½Ð° Ð²ÐµÑ€ÑÐ¸Ñ</u></a>';
  </script>
  <div class="hosting">Â© <strong>imot.bg</strong> Ð¿Ð¾Ð»Ð·Ð²Ð° Ð¸ Ð¿Ñ€ÐµÐ¿Ð¾Ñ€ÑŠÑ‡Ð²Ð° <strong>Ñ…Ð¾ÑÑ‚Ð¸Ð½Ð³ ÑƒÑÐ»ÑƒÐ³Ð¸Ñ‚Ðµ</strong> Ð½Ð° <a href="https://bulinfo.net" target="_blank"><strong><img src="//www.imot.bg/images/picturess/bulinfo-logo.svg" alt="Bulinfo.net"></strong></a></div>
  <div class="follow-us">
    <div>Ð¡Ð»ÐµÐ´Ð²Ð°Ð¹Ñ‚Ðµ Ð½Ð¸ Ð²:</div>
    <a href="https://www.instagram.com/imot.bg/?igsh=MXd6emtpd3kyb2E3dQ%3D%3D" class="follow-us-instagram" target="_blank" title="ÐŸÐ¾ÑÐ»ÐµÐ´Ð²Ð°Ð¹ Ð½Ð¸ Ð² Instagram"></a>
    <a href="https://www.tiktok.com/@imot_bg?_t=ZN-8yTupjIOizC" class="follow-us-tiktok" target="_blank" title="ÐŸÐ¾ÑÐ»ÐµÐ´Ð²Ð°Ð¹ Ð½Ð¸ Ð² TikTok"></a>
    <a href="https://www.facebook.com/imot.bg" class="follow-us-facebook" target="_blank" title="ÐŸÐ¾ÑÐ»ÐµÐ´Ð²Ð°Ð¹ Ð½Ð¸ Ð² Facebook"></a>
    <a href="https://www.youtube.com/@Imot.bg_Official" class="follow-us-youtube" target="_blank" title="ÐŸÐ¾ÑÐ»ÐµÐ´Ð²Ð°Ð¹ Ð½Ð¸ Ð² YouTube"></a>
  </div>
  



      </div>

      <br>
      <div id="logtable" class="LB-white-content" style="width:530px; height:450px;"></div>
      <div id="sendpmessage" class="LB-white-content" style="width:590px; height:465px; left: 20%; position: absolute; top: 50px; display: none;"></div>

      <script type="text/javascript" src="/jss/sticky.js"></script>

      <script>cleverLinks();</script>

      <!-- (C)2000-2014 Gemius SA - gemiusAudience / imot.bg / Home Page -->
      <script type="text/javascript">
      <!--//--><![CDATA[//><!--
      var pp_gemius_identifier = 'p8ZKf3ughze7qeDBCa1hhJQ5XkGiDSOqlz_uKt6qu_X.M7';
      // lines below shouldn't be edited
      function gemius_pending(i) { window[i] = window[i] || function() {var x = window[i+'_pdata'] = window[i+'_pdata'] || []; x[x.length]=arguments;};};
      gemius_pending('gemius_hit'); gemius_pending('gemius_event'); gemius_pending('pp_gemius_hit'); gemius_pending('pp_gemius_event');
      (function(d,t) {try {var gt=d.createElement(t),s=d.getElementsByTagName(t)[0],l='http'+((location.protocol=='https:')?'s':''); gt.setAttribute('async','async');
      gt.setAttribute('defer','defer'); gt.src=l+'://gabg.hit.gemius.pl/xgemius.js'; s.parentNode.insertBefore(gt,s);} catch (e) {}})(document,'script');
      //--><!]]>
      </script>

      <!--  -->
      </body>
    </html>
    

=========================================
FILE: ./manual_session_audit.py
=========================================
import httpx
from bs4 import BeautifulSoup

def manual_audit(url, cookie_string):
    # This cookie_string you will copy from your real phone browser
    headers = {
        "User-Agent": "Mozilla/5.0 (Linux; Android 10; K) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Mobile Safari/537.36",
        "Cookie": cookie_string,
        "Accept-Language": "bg-BG,bg;q=0.9",
        "Referer": "https://www.imot.bg/"
    }

    with httpx.Client(headers=headers, timeout=15.0) as client:
        resp = client.get(url)
        content = resp.content.decode('windows-1251', errors='replace')
        
        if "captcha" in content.lower():
            print("[-] FAIL: Cookie was rejected or expired.")
        else:
            print("[+] SUCCESS: Bypass confirmed via Session Injection.")
            soup = BeautifulSoup(content, 'html.parser')
            price = soup.find(id='price_obs')
            if price:
                print(f"    [!!!] REVEALED PRICE: {price.text.strip()}")

if __name__ == "__main__":
    # YOU NEED TO FILL THIS FROM YOUR BROWSER
    MY_COOKIE = "imot_session_redirect=...; sid=...;" 
    manual_audit("https://www.imot.bg/pcgi/imot.cgi?act=5&adv=1c171899111", MY_COOKIE)


=========================================
FILE: ./scraper_service.py
=========================================
import re
import json
from bs4 import BeautifulSoup
from forensics_engine import ListingForensics
from risk_engine import RiskEngine

class ScraperService:
    def __init__(self):
        self.forensics = ListingForensics()
        self.risk_engine = RiskEngine()

    def parse_imot_bg_html(self, html_content: str, url: str = ""):
        """
        Parses raw HTML from imot.bg and runs the full forensic audit.
        """
        soup = BeautifulSoup(html_content, 'html.parser')
        
        # 1. Basic Extraction
        try:
            title_tag = soup.find('h1')
            title = title_tag.text.strip() if title_tag else "Unknown"
            
            # Price extraction (handles "139 000 â‚¬")
            price_tag = soup.find(id='price')
            price_text = price_tag.text.strip() if price_tag else "0"
            price_clean = re.sub(r'[^\d]', '', price_text)
            price = float(price_clean) if price_clean else 0.0
            
            # Description extraction
            desc_tag = soup.find(id='description_div')
            description = desc_tag.text.strip() if desc_tag else ""
            
            # Specification extraction (Area, Floor, Type)
            # Imot.bg usually puts these in an 'info' block or params
            # We look for "ÐŸÐ»Ð¾Ñ‰:" text
            area = 0
            floor = ""
            construction = ""
            
            # Simple text scanning for demo purposes (imot.bg structure varies)
            full_text = soup.get_text()
            
            area_match = re.search(r'ÐŸÐ»Ð¾Ñ‰:\s*(\d+)', full_text)
            if area_match:
                area = int(area_match.group(1))
                
            floor_match = re.search(r'Ð•Ñ‚Ð°Ð¶:\s*(.*)', full_text)
            if floor_match:
                floor = floor_match.group(1).split('\n')[0].strip()
                
            type_match = re.search(r'Ð’Ð¸Ð´ Ð¸Ð¼Ð¾Ñ‚:\s*(.*)', full_text)
            listing_type = "2-Ð¡Ð¢ÐÐ•Ð" if "2-Ð¡Ð¢ÐÐ•Ð" in title.upper() else "UNKNOWN"

        except Exception as e:
            return {"error": f"Parsing failed: {str(e)}"}

        # 2. Forensic Analysis
        flags = self.forensics.analyze_text(description, title)
        
        # Check for VAT field specifically in HTML (sometimes outside description)
        if "ÐÐµ ÑÐµ Ð½Ð°Ñ‡Ð¸ÑÐ»ÑÐ²Ð° Ð”Ð”Ð¡" in full_text and "VAT_EXCLUDED" not in flags:
             # Actually "ÐÐµ ÑÐµ Ð½Ð°Ñ‡Ð¸ÑÐ»ÑÐ²Ð° Ð”Ð”Ð¡" usually means NO VAT is owed (Private seller)
             # But "Ð¦ÐµÐ½Ð°Ñ‚Ð° Ðµ Ð±ÐµÐ· Ð”Ð”Ð¡" means +20%. 
             # Let's trust the forensics engine regex for the tricky ones.
             pass

        # 3. Normalize Price
        real_price = self.forensics.normalize_price(price, flags)

        # 4. Risk Calculation
        listing_data = {
            "type": listing_type,
            "area": area,
            "price": price,
            "floor": floor
        }
        
        risk_report = self.risk_engine.calculate_risk_score(listing_data, flags)

        # 5. Construct Final Output
        return {
            "meta": {
                "url": url,
                "parsed_at": "now"
            },
            "basic_info": {
                "title": title,
                "advertised_price": price,
                "real_price_estimate": real_price,
                "area": area,
                "floor": floor
            },
            "forensics": {
                "detected_flags": flags,
                "risk_audit": risk_report
            },
            "ai_summary": self.generate_summary(risk_report, real_price, area)
        }

    def generate_summary(self, risk_report, price, area):
        if risk_report['verdict'] == "CRITICAL":
            return "DO NOT BUY. This property has critical red flags."
        if risk_report['verdict'] == "WARNING":
            return "PROCEED WITH CAUTION. Significant discrepancies detected."
        return "Low risk detected based on automated audit."

# --- SIMULATION BLOCK (For testing) ---
if __name__ == "__main__":
    # Simulating the Lyulin 4 "Garsoniera" from the user dump
    mock_html = """
    <html>
        <h1>ÐŸÑ€Ð¾Ð´Ð°Ð²Ð° 2-Ð¡Ð¢ÐÐ•Ð, Ð³Ñ€Ð°Ð´ Ð¡Ð¾Ñ„Ð¸Ñ, Ð›ÑŽÐ»Ð¸Ð½ 4</h1>
        <div id="price">139 000 â‚¬</div>
        <div>ÐŸÐ»Ð¾Ñ‰: 47 m2</div>
        <div>Ð•Ñ‚Ð°Ð¶: 3-Ñ‚Ð¸ Ð¾Ñ‚ 8</div>
        <div id="description_div">
            ÐŸÑ€Ð¾Ð´Ð°Ð²Ð° Ð¼Ð°Ð»Ð¾Ð¼ÐµÑ€ÐµÐ½ Ð´Ð²ÑƒÑÑ‚Ð°ÐµÐ½, Ð¿Ñ€ÐµÑƒÑÑ‚Ñ€Ð¾ÐµÐ½Ð° Ð³Ð°Ñ€ÑÐ¾Ð½Ð¸ÐµÑ€Ð°. 
            Ð–Ð¸Ð»Ð¸Ñ‰ÐµÑ‚Ð¾ Ðµ ÑÐ»ÐµÐ´ Ð»ÑƒÐºÑ Ñ€ÐµÐ¼Ð¾Ð½Ñ‚. ÐÐ°Ð¹-Ð´Ð¾Ð±Ñ€Ð¸ÑÑ‚ ÐµÑ‚Ð°Ð¶.
        </div>
        <div>ÐÐµ ÑÐµ Ð½Ð°Ñ‡Ð¸ÑÐ»ÑÐ²Ð° Ð”Ð”Ð¡</div>
    </html>
    """
    
    service = ScraperService()
    result = service.parse_imot_bg_html(mock_html, "http://test.url")
    print(json.dumps(result, indent=2, ensure_ascii=False))
