--- GLASHAUS PROJECT DUMP ---
Thu Dec 18 12:13:01 EET 2025
Structure:
.
./docs
./docs/ARCHITECTURE.md
./docs/api_contract.yaml
./src
./src/api
./src/api/routes.py
./src/core
./src/core/config.py
./src/services
./src/models
./src/__init__.py
./src/main.py
./scripts
./scripts/context_dump.sh
./prompts
./prompts/detective_prompt_v1.md
./db
./db/schema_v1.sql
./README.md
./glashaus_context.txt
./requirements.txt


--- FILE CONTENTS ---


=========================================
FILE: ./docs/ARCHITECTURE.md
=========================================
# System Architecture

## Core Logic Flow (Cost Optimized)
1. **Ingest:** Scraper Service fetches URL.
2. **Analysis Tier 1 (Cheap):** Text Extraction (Gemini Flash).
   - *Goal:* Find Address in text.
   - *Cost:* ~$0.04/run.
3. **Gatekeeper:** Confidence Check (>90%).
4. **Analysis Tier 2 (Expensive):** Visual Detective (Gemini Pro).
   - *Trigger:* Only if Tier 1 fails.
   - *Goal:* Identify building via Facade/Landmarks/Geofencing.
   - *Cost:* ~$0.22/run.
5. **Verification:** Cross-reference extracted Address vs Cadastre API.

## Tech Stack
- **Lang:** Python (FastAPI) or Java (Spring Boot) - TBD
- **DB:** PostgreSQL + PostGIS (Geospatial extensions)
- **Queue:** Redis (Task offloading)


=========================================
FILE: ./docs/api_contract.yaml
=========================================
openapi: 3.0.0
info:
  title: Glashaus API
  version: 0.1.0
paths:
  /audit/url:
    post:
      summary: Initiate an Audit for a specific Listing URL
      requestBody:
        content:
          application/json:
            schema:
              type: object
              properties:
                url:
                  type: string
                  format: uri
      responses:
        '200':
          description: Audit Complete
          content:
            application/json:
              schema:
                type: object
                properties:
                  report_id:
                    type: integer
                  risk_score:
                    type: integer
                  verified_address:
                    type: string
                  ai_reasoning:
                    type: array
                    items:
                      type: string


=========================================
FILE: ./src/api/routes.py
=========================================
from fastapi import APIRouter, HTTPException
from pydantic import BaseModel, HttpUrl

router = APIRouter()

class AuditRequest(BaseModel):
    url: HttpUrl

class AuditResponse(BaseModel):
    report_id: str
    risk_score: int
    status: str

@router.post("/audit", response_model=AuditResponse)
async def initiate_audit(request: AuditRequest):
    """
    Receives a Listing URL and triggers the Intelligence Pipeline.
    """
    print(f"--> Ingesting Target: {request.url}")
    
    # TODO: Connect to Redis Queue here
    # TODO: Connect to Scraper Service
    
    return {
        "report_id": "REQ-12345", 
        "risk_score": 0, 
        "status": "PROCESSING_STARTED"
    }


=========================================
FILE: ./src/core/config.py
=========================================
import os

class Settings:
    PROJECT_NAME: str = "Glashaus"
    VERSION: str = "0.1.0"
    
    # Database
    POSTGRES_USER: str = os.getenv("POSTGRES_USER", "postgres")
    POSTGRES_PASSWORD: str = os.getenv("POSTGRES_PASSWORD", "changeme")
    POSTGRES_SERVER: str = os.getenv("POSTGRES_SERVER", "localhost")
    POSTGRES_DB: str = os.getenv("POSTGRES_DB", "glashaus")
    
    # AI Keys
    GEMINI_API_KEY: str = os.getenv("GEMINI_API_KEY", "")

settings = Settings()


=========================================
FILE: ./src/__init__.py
=========================================


=========================================
FILE: ./src/main.py
=========================================
from fastapi import FastAPI
from src.api import routes

app = FastAPI(
    title="Glashaus API",
    description="Automated Real Estate Due Diligence Engine",
    version="0.1.0"
)

# Register Router
app.include_router(routes.router)

@app.get("/")
def health_check():
    return {"status": "operational", "system": "GLASHAUS"}

if __name__ == "__main__":
    import uvicorn
    # Hot reload enabled for dev
    uvicorn.run("src.main:app", host="0.0.0.0", port=8000, reload=True)


=========================================
FILE: ./scripts/context_dump.sh
=========================================
#!/bin/bash
# Scans the repo and dumps text files for LLM context
output="glashaus_context.txt"
echo "--- GLASHAUS PROJECT DUMP ---" > "$output"
date >> "$output"
echo "Structure:" >> "$output"
tree -L 3 -I '.git' >> "$output" 2>/dev/null || find . -maxdepth 3 -not -path '*/.*' >> "$output"

echo -e "\n\n--- FILE CONTENTS ---" >> "$output"
find . -type f \
    -not -path '*/.*' \
    -not -path './glashaus_context.txt' \
    -not -name '*.png' \
    -not -name '*.jpg' \
    | while read -r file; do
    echo -e "\n\n=========================================" >> "$output"
    echo "FILE: $file" >> "$output"
    echo "=========================================" >> "$output"
    cat "$file" >> "$output"
done

echo "Dump complete. Copy contents of $output"


=========================================
FILE: ./prompts/detective_prompt_v1.md
=========================================
# Role: Geospatial Detective
You are an expert Investigator. Your task is to identify the specific building address of a real estate listing based on limited metadata and photos.

## Input Data
- **Listing Text:** {text_raw}
- **Images:** {image_list}
- **Neighborhood Hint:** {neighborhood}

## Logic Constraints
1. **Fact vs Guess:** Distinguish between explicitly stated streets and visual deductions.
2. **The "Red House" Rule:** Look for unique landmarks in the "View from Window" photos.
3. **Facade Matching:** Describe the balcony curve/color and estimate construction era.

## Output Format (JSON Only)
{
  "address_prediction": "String",
  "confidence": 0-100,
  "reasoning_steps": [
    "Identified beige facade matching 2003 construction style.",
    "Located restaurant 'Chefs' on ground floor visible in photo 3.",
    "Triangulated address to Ul. Lyubata 13."
  ],
  "unit_type_discrepancy": "Apartment vs Atelier" (if applicable)
}


=========================================
FILE: ./db/schema_v1.sql
=========================================
-- Enable GIS extensions for location logic
CREATE EXTENSION IF NOT EXISTS postgis;

CREATE TABLE buildings (
    id SERIAL PRIMARY KEY,
    cadastre_id VARCHAR(50) UNIQUE NOT NULL, -- The official identifier
    address_street VARCHAR(255),
    address_number VARCHAR(50),
    neighborhood VARCHAR(100),
    gps_coordinates GEOMETRY(Point, 4326),
    construction_year INT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE TABLE listings (
    id SERIAL PRIMARY KEY,
    source_url TEXT UNIQUE NOT NULL,
    price_bgn DECIMAL(12, 2),
    advertised_area_sqm DECIMAL(10, 2),
    description_raw TEXT,
    scraped_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE TABLE reports (
    id SERIAL PRIMARY KEY,
    listing_id INT REFERENCES listings(id),
    building_id INT REFERENCES buildings(id),
    risk_score INT, -- 0 to 100 (100 is Toxic)
    is_address_verified BOOLEAN DEFAULT FALSE,
    discrepancy_details JSONB, -- Stores the "Apartment vs Atelier" logic
    cost_to_generate DECIMAL(10, 4) -- Tracking the $0.22 API cost
);


=========================================
FILE: ./README.md
=========================================
# GLASHAUS: The Real Estate Integrity Engine

## Mission
To eliminate information asymmetry in the Sofia real estate market via automated due diligence.
We leverage OSINT, LLM reasoning, and Official Registry cross-referencing.

## Architecture
- **Text Layer:** Gemini Flash (Cost optimized)
- **Vision Layer:** Gemini Pro (Geospatial reasoning)
- **Data Layer:** PostgreSQL (Structured) + S3 (Archives)

## Status
- **Phase:** Pre-Alpha / Architectural Blueprint
- **Deploy Target:** Jan 2026 (Launch)


=========================================
FILE: ./requirements.txt
=========================================
fastapi==0.109.0
uvicorn==0.27.0
sqlalchemy==2.0.25
psycopg2-binary==2.9.9
httpx==0.26.0
pydantic==2.6.0
pydantic-settings==2.1.0
google-generativeai==0.3.2
beautifulsoup4==4.12.3
